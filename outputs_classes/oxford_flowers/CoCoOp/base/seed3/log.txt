***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoCoOp/vit_b16_c4_ep50_bs4.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/base2new/train_base/oxford_flowers/shots_16/CoCoOp/vit_b16_c4_ep50_bs4/seed3
resume: 
root: /mnt/hdd/DATA
seed: 3
source_domains: None
target_domains: None
trainer: CoCoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: /mnt/hdd/DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/base2new/train_base/oxford_flowers/shots_16/CoCoOp/vit_b16_c4_ep50_bs4/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  IVLP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 2
    N_CTX_VISION: 2
    PREC: fp16
    PROMPT_DEPTH_TEXT: 9
    PROMPT_DEPTH_VISION: 9
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MAPLE:
    CTX_INIT: a photo of a
    N_CTX: 2
    PREC: fp16
    PROMPT_DEPTH: 9
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoCoOp
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
  VPT:
    CTX_INIT: a photo of a
    N_CTX_VISION: 2
    PREC: fp16
    PROMPT_DEPTH_VISION: 1
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.2.2+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Debian GNU/Linux 12 (bookworm) (x86_64)
GCC version: (Debian 12.2.0-14) 12.2.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.36

Python version: 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (64-bit runtime)
Python platform: Linux-6.5.13-3-pve-x86_64-with-glibc2.36
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A800 80GB PCIe
GPU 1: NVIDIA A800 80GB PCIe

Nvidia driver version: 525.147.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      46 bits physical, 57 bits virtual
Byte Order:                         Little Endian
CPU(s):                             64
On-line CPU(s) list:                0-24,26-32
Off-line CPU(s) list:               25,33-63
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz
CPU family:                         6
Model:                              106
Thread(s) per core:                 2
Core(s) per socket:                 16
Socket(s):                          2
Stepping:                           6
CPU(s) scaling MHz:                 98%
CPU max MHz:                        3500.0000
CPU min MHz:                        800.0000
BogoMIPS:                           5800.00
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts vnmi avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid fsrm md_clear pconfig flush_l1d arch_capabilities
Virtualization:                     VT-x
L1d cache:                          1.5 MiB (32 instances)
L1i cache:                          1 MiB (32 instances)
L2 cache:                           40 MiB (32 instances)
L3 cache:                           48 MiB (2 instances)
NUMA node(s):                       2
NUMA node0 CPU(s):                  0-15,32-47
NUMA node1 CPU(s):                  16-31,48-63
Vulnerability Gather data sampling: Vulnerable: No microcode
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable
Vulnerability Retbleed:             Not affected
Vulnerability Spec rstack overflow: Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.26.4
[pip3] torch==2.2.2
[pip3] torchaudio==2.2.2
[pip3] torchvision==0.17.2
[pip3] triton==2.2.0
[conda] Could not collect
        Pillow (10.3.0)

Loading trainer: CoCoOp
Loading dataset: OxfordFlowers
Reading split from /mnt/hdd/DATA/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /mnt/hdd/DATA/oxford_flowers/split_fewshot/shot_16_shuffled-seed_3.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      204
# test     1,241
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'prompt_learner.meta_net.linear1.bias', 'prompt_learner.meta_net.linear2.weight', 'prompt_learner.meta_net.linear2.bias', 'prompt_learner.ctx', 'prompt_learner.meta_net.linear1.weight'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/base2new/train_base/oxford_flowers/shots_16/CoCoOp/vit_b16_c4_ep50_bs4/seed3/tensorboard)
epoch [1/50] batch [20/204] time 0.071 (0.204) data 0.000 (0.016) loss 7.1758 (2.9745) lr 1.0000e-05 eta 0:34:36
epoch [1/50] batch [40/204] time 0.069 (0.137) data 0.000 (0.008) loss 2.4766 (2.8748) lr 1.0000e-05 eta 0:23:14
epoch [1/50] batch [60/204] time 0.071 (0.115) data 0.001 (0.005) loss 1.1992 (2.8069) lr 1.0000e-05 eta 0:19:25
epoch [1/50] batch [80/204] time 0.071 (0.104) data 0.000 (0.004) loss 2.9902 (2.6491) lr 1.0000e-05 eta 0:17:32
epoch [1/50] batch [100/204] time 0.071 (0.097) data 0.000 (0.003) loss 0.6748 (2.5984) lr 1.0000e-05 eta 0:16:24
epoch [1/50] batch [120/204] time 0.071 (0.093) data 0.000 (0.003) loss 3.3340 (2.6391) lr 1.0000e-05 eta 0:15:37
epoch [1/50] batch [140/204] time 0.071 (0.090) data 0.000 (0.002) loss 0.4929 (2.5333) lr 1.0000e-05 eta 0:15:04
epoch [1/50] batch [160/204] time 0.071 (0.088) data 0.000 (0.002) loss 1.9863 (2.4979) lr 1.0000e-05 eta 0:14:39
epoch [1/50] batch [180/204] time 0.070 (0.086) data 0.000 (0.002) loss 0.3147 (2.5452) lr 1.0000e-05 eta 0:14:18
epoch [1/50] batch [200/204] time 0.069 (0.084) data 0.000 (0.002) loss 1.4209 (2.4667) lr 1.0000e-05 eta 0:14:01
epoch [2/50] batch [20/204] time 0.070 (0.096) data 0.000 (0.025) loss 0.0624 (1.2311) lr 2.0000e-03 eta 0:15:53
epoch [2/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 2.1309 (1.2002) lr 2.0000e-03 eta 0:13:45
epoch [2/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.2896 (1.2305) lr 2.0000e-03 eta 0:13:02
epoch [2/50] batch [80/204] time 0.070 (0.077) data 0.000 (0.006) loss 1.0166 (1.2030) lr 2.0000e-03 eta 0:12:39
epoch [2/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.7134 (1.2131) lr 2.0000e-03 eta 0:12:25
epoch [2/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 1.7637 (1.2063) lr 2.0000e-03 eta 0:12:15
epoch [2/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 1.9375 (1.2081) lr 2.0000e-03 eta 0:12:08
epoch [2/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.3789 (1.1699) lr 2.0000e-03 eta 0:12:02
epoch [2/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.6396 (1.1607) lr 2.0000e-03 eta 0:11:57
epoch [2/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3071 (1.1546) lr 2.0000e-03 eta 0:11:52
epoch [3/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.6821 (0.9726) lr 1.9980e-03 eta 0:15:30
epoch [3/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.3577 (0.8783) lr 1.9980e-03 eta 0:13:26
epoch [3/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 2.5137 (0.8932) lr 1.9980e-03 eta 0:12:44
epoch [3/50] batch [80/204] time 0.071 (0.076) data 0.000 (0.006) loss 0.2169 (0.8946) lr 1.9980e-03 eta 0:12:22
epoch [3/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1656 (0.8783) lr 1.9980e-03 eta 0:12:08
epoch [3/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.6133 (0.8852) lr 1.9980e-03 eta 0:11:59
epoch [3/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1315 (0.8507) lr 1.9980e-03 eta 0:11:52
epoch [3/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0388 (0.8592) lr 1.9980e-03 eta 0:11:46
epoch [3/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4639 (0.8773) lr 1.9980e-03 eta 0:11:41
epoch [3/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.6826 (0.8626) lr 1.9980e-03 eta 0:11:36
epoch [4/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.6084 (0.6972) lr 1.9921e-03 eta 0:15:07
epoch [4/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.1237 (0.7088) lr 1.9921e-03 eta 0:13:07
epoch [4/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.5312 (0.7159) lr 1.9921e-03 eta 0:12:26
epoch [4/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4509 (0.7244) lr 1.9921e-03 eta 0:12:05
epoch [4/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.7114 (0.7147) lr 1.9921e-03 eta 0:11:52
epoch [4/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3682 (0.7193) lr 1.9921e-03 eta 0:11:43
epoch [4/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3511 (0.7053) lr 1.9921e-03 eta 0:11:36
epoch [4/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1677 (0.6989) lr 1.9921e-03 eta 0:11:30
epoch [4/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.0234 (0.6864) lr 1.9921e-03 eta 0:11:25
epoch [4/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.6411 (0.6734) lr 1.9921e-03 eta 0:11:21
epoch [5/50] batch [20/204] time 0.071 (0.096) data 0.000 (0.025) loss 0.2468 (0.8514) lr 1.9823e-03 eta 0:14:58
epoch [5/50] batch [40/204] time 0.071 (0.083) data 0.000 (0.012) loss 0.2482 (0.6878) lr 1.9823e-03 eta 0:12:58
epoch [5/50] batch [60/204] time 0.070 (0.079) data 0.001 (0.008) loss 0.4290 (0.7428) lr 1.9823e-03 eta 0:12:16
epoch [5/50] batch [80/204] time 0.070 (0.077) data 0.000 (0.006) loss 0.3809 (0.7372) lr 1.9823e-03 eta 0:11:55
epoch [5/50] batch [100/204] time 0.071 (0.076) data 0.000 (0.005) loss 0.3230 (0.6939) lr 1.9823e-03 eta 0:11:41
epoch [5/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 1.8086 (0.6946) lr 1.9823e-03 eta 0:11:32
epoch [5/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 0.0273 (0.6579) lr 1.9823e-03 eta 0:11:25
epoch [5/50] batch [160/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.1116 (0.6635) lr 1.9823e-03 eta 0:11:19
epoch [5/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.5312 (0.6776) lr 1.9823e-03 eta 0:11:15
epoch [5/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.2050 (0.6543) lr 1.9823e-03 eta 0:11:10
epoch [6/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.4841 (0.5585) lr 1.9686e-03 eta 0:14:32
epoch [6/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0645 (0.5737) lr 1.9686e-03 eta 0:12:35
epoch [6/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 1.2881 (0.5788) lr 1.9686e-03 eta 0:11:55
epoch [6/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.5571 (0.5616) lr 1.9686e-03 eta 0:11:34
epoch [6/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2388 (0.5707) lr 1.9686e-03 eta 0:11:21
epoch [6/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.2783 (0.5562) lr 1.9686e-03 eta 0:11:12
epoch [6/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.7524 (0.5594) lr 1.9686e-03 eta 0:11:06
epoch [6/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 2.9863 (0.5881) lr 1.9686e-03 eta 0:11:00
epoch [6/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.6104 (0.5917) lr 1.9686e-03 eta 0:10:56
epoch [6/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0109 (0.6015) lr 1.9686e-03 eta 0:10:51
epoch [7/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 1.5938 (0.4075) lr 1.9511e-03 eta 0:14:12
epoch [7/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.1030 (0.5407) lr 1.9511e-03 eta 0:12:17
epoch [7/50] batch [60/204] time 0.070 (0.078) data 0.001 (0.008) loss 0.8633 (0.4932) lr 1.9511e-03 eta 0:11:38
epoch [7/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.3149 (0.4691) lr 1.9511e-03 eta 0:11:18
epoch [7/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 1.4043 (0.4955) lr 1.9511e-03 eta 0:11:05
epoch [7/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.5962 (0.5265) lr 1.9511e-03 eta 0:10:56
epoch [7/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.2947 (0.5411) lr 1.9511e-03 eta 0:10:50
epoch [7/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1498 (0.5458) lr 1.9511e-03 eta 0:10:44
epoch [7/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0772 (0.5415) lr 1.9511e-03 eta 0:10:39
epoch [7/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 1.1328 (0.5590) lr 1.9511e-03 eta 0:10:35
epoch [8/50] batch [20/204] time 0.070 (0.094) data 0.000 (0.024) loss 0.2710 (0.4104) lr 1.9298e-03 eta 0:13:45
epoch [8/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.8672 (0.4154) lr 1.9298e-03 eta 0:11:56
epoch [8/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2869 (0.5488) lr 1.9298e-03 eta 0:11:19
epoch [8/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4478 (0.5153) lr 1.9298e-03 eta 0:11:00
epoch [8/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.6743 (0.4887) lr 1.9298e-03 eta 0:10:48
epoch [8/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0884 (0.5087) lr 1.9298e-03 eta 0:10:40
epoch [8/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.3779 (0.5224) lr 1.9298e-03 eta 0:10:33
epoch [8/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.8506 (0.5155) lr 1.9298e-03 eta 0:10:28
epoch [8/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.6104 (0.5212) lr 1.9298e-03 eta 0:10:24
epoch [8/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.002) loss 0.5996 (0.5089) lr 1.9298e-03 eta 0:10:19
epoch [9/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.8828 (0.4325) lr 1.9048e-03 eta 0:13:32
epoch [9/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.2981 (0.4063) lr 1.9048e-03 eta 0:11:43
epoch [9/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2913 (0.4463) lr 1.9048e-03 eta 0:11:06
epoch [9/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.1736 (0.4419) lr 1.9048e-03 eta 0:10:47
epoch [9/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1595 (0.4374) lr 1.9048e-03 eta 0:10:35
epoch [9/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.5679 (0.4404) lr 1.9048e-03 eta 0:10:26
epoch [9/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.6792 (0.4272) lr 1.9048e-03 eta 0:10:20
epoch [9/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.3425 (0.4365) lr 1.9048e-03 eta 0:10:14
epoch [9/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.3435 (0.4387) lr 1.9048e-03 eta 0:10:10
epoch [9/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.0197 (0.4468) lr 1.9048e-03 eta 0:10:06
epoch [10/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1429 (0.4610) lr 1.8763e-03 eta 0:13:11
epoch [10/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.5493 (0.5088) lr 1.8763e-03 eta 0:11:25
epoch [10/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2045 (0.4658) lr 1.8763e-03 eta 0:10:49
epoch [10/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.2283 (0.4474) lr 1.8763e-03 eta 0:10:30
epoch [10/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.5679 (0.4571) lr 1.8763e-03 eta 0:10:18
epoch [10/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.6758 (0.4710) lr 1.8763e-03 eta 0:10:10
epoch [10/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3667 (0.4793) lr 1.8763e-03 eta 0:10:11
epoch [10/50] batch [160/204] time 0.070 (0.074) data 0.000 (0.003) loss 0.5527 (0.5111) lr 1.8763e-03 eta 0:10:05
epoch [10/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1188 (0.5164) lr 1.8763e-03 eta 0:10:00
epoch [10/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3215 (0.5010) lr 1.8763e-03 eta 0:09:55
epoch [11/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.5601 (0.3948) lr 1.8443e-03 eta 0:12:53
epoch [11/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.3979 (0.4313) lr 1.8443e-03 eta 0:11:10
epoch [11/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 1.3818 (0.4954) lr 1.8443e-03 eta 0:10:35
epoch [11/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.2722 (0.5147) lr 1.8443e-03 eta 0:10:17
epoch [11/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1300 (0.4916) lr 1.8443e-03 eta 0:10:05
epoch [11/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3345 (0.4901) lr 1.8443e-03 eta 0:09:57
epoch [11/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.2778 (0.4878) lr 1.8443e-03 eta 0:09:50
epoch [11/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1194 (0.4788) lr 1.8443e-03 eta 0:09:45
epoch [11/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0528 (0.4661) lr 1.8443e-03 eta 0:09:41
epoch [11/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.5474 (0.4643) lr 1.8443e-03 eta 0:09:37
epoch [12/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.5830 (0.4842) lr 1.8090e-03 eta 0:12:34
epoch [12/50] batch [40/204] time 0.071 (0.083) data 0.000 (0.012) loss 0.0731 (0.3747) lr 1.8090e-03 eta 0:10:54
epoch [12/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.1301 (0.3909) lr 1.8090e-03 eta 0:10:20
epoch [12/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 0.1322 (0.4035) lr 1.8090e-03 eta 0:10:03
epoch [12/50] batch [100/204] time 0.071 (0.075) data 0.000 (0.005) loss 0.0658 (0.4291) lr 1.8090e-03 eta 0:09:51
epoch [12/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0135 (0.4134) lr 1.8090e-03 eta 0:09:43
epoch [12/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0053 (0.4086) lr 1.8090e-03 eta 0:09:37
epoch [12/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1273 (0.4143) lr 1.8090e-03 eta 0:09:32
epoch [12/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2302 (0.4018) lr 1.8090e-03 eta 0:09:28
epoch [12/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 1.0566 (0.4203) lr 1.8090e-03 eta 0:09:24
epoch [13/50] batch [20/204] time 0.071 (0.096) data 0.000 (0.024) loss 0.1165 (0.4704) lr 1.7705e-03 eta 0:12:19
epoch [13/50] batch [40/204] time 0.072 (0.083) data 0.000 (0.012) loss 0.2534 (0.4548) lr 1.7705e-03 eta 0:10:43
epoch [13/50] batch [60/204] time 0.071 (0.079) data 0.001 (0.008) loss 0.1667 (0.4012) lr 1.7705e-03 eta 0:10:10
epoch [13/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 0.1058 (0.3981) lr 1.7705e-03 eta 0:09:53
epoch [13/50] batch [100/204] time 0.071 (0.076) data 0.000 (0.005) loss 0.1039 (0.3979) lr 1.7705e-03 eta 0:09:42
epoch [13/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 1.6709 (0.4027) lr 1.7705e-03 eta 0:09:34
epoch [13/50] batch [140/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.7861 (0.3955) lr 1.7705e-03 eta 0:09:27
epoch [13/50] batch [160/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.0779 (0.3859) lr 1.7705e-03 eta 0:09:22
epoch [13/50] batch [180/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.1636 (0.3875) lr 1.7705e-03 eta 0:09:18
epoch [13/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3770 (0.3829) lr 1.7705e-03 eta 0:09:13
epoch [14/50] batch [20/204] time 0.071 (0.096) data 0.000 (0.024) loss 0.2380 (0.3645) lr 1.7290e-03 eta 0:12:00
epoch [14/50] batch [40/204] time 0.071 (0.083) data 0.000 (0.012) loss 0.2375 (0.3774) lr 1.7290e-03 eta 0:10:25
epoch [14/50] batch [60/204] time 0.071 (0.079) data 0.000 (0.008) loss 0.1718 (0.3322) lr 1.7290e-03 eta 0:09:52
epoch [14/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 1.3789 (0.3659) lr 1.7290e-03 eta 0:09:35
epoch [14/50] batch [100/204] time 0.071 (0.076) data 0.000 (0.005) loss 0.1218 (0.3789) lr 1.7290e-03 eta 0:09:24
epoch [14/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.2086 (0.3961) lr 1.7290e-03 eta 0:09:17
epoch [14/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 0.0964 (0.4161) lr 1.7290e-03 eta 0:09:11
epoch [14/50] batch [160/204] time 0.071 (0.074) data 0.000 (0.003) loss 2.0723 (0.4407) lr 1.7290e-03 eta 0:09:06
epoch [14/50] batch [180/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.5439 (0.4623) lr 1.7290e-03 eta 0:09:02
epoch [14/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.4124 (0.4624) lr 1.7290e-03 eta 0:08:58
epoch [15/50] batch [20/204] time 0.070 (0.096) data 0.000 (0.024) loss 0.2177 (0.5091) lr 1.6845e-03 eta 0:11:40
epoch [15/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 1.0898 (0.4996) lr 1.6845e-03 eta 0:10:06
epoch [15/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.1923 (0.4784) lr 1.6845e-03 eta 0:09:34
epoch [15/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 0.1210 (0.4979) lr 1.6845e-03 eta 0:09:17
epoch [15/50] batch [100/204] time 0.070 (0.076) data 0.000 (0.005) loss 1.6543 (0.4707) lr 1.6845e-03 eta 0:09:07
epoch [15/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.0708 (0.4393) lr 1.6845e-03 eta 0:08:59
epoch [15/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.9873 (0.4299) lr 1.6845e-03 eta 0:08:53
epoch [15/50] batch [160/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.8716 (0.4371) lr 1.6845e-03 eta 0:08:49
epoch [15/50] batch [180/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.5098 (0.4296) lr 1.6845e-03 eta 0:08:45
epoch [15/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0589 (0.4432) lr 1.6845e-03 eta 0:08:41
epoch [16/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.0315 (0.3772) lr 1.6374e-03 eta 0:11:17
epoch [16/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0738 (0.4151) lr 1.6374e-03 eta 0:09:46
epoch [16/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1606 (0.4159) lr 1.6374e-03 eta 0:09:15
epoch [16/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4888 (0.4604) lr 1.6374e-03 eta 0:08:59
epoch [16/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1896 (0.4301) lr 1.6374e-03 eta 0:08:48
epoch [16/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.5542 (0.4399) lr 1.6374e-03 eta 0:08:41
epoch [16/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 0.0644 (0.4376) lr 1.6374e-03 eta 0:08:35
epoch [16/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1420 (0.4546) lr 1.6374e-03 eta 0:08:31
epoch [16/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.9937 (0.4539) lr 1.6374e-03 eta 0:08:27
epoch [16/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3438 (0.4583) lr 1.6374e-03 eta 0:08:23
epoch [17/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.6963 (0.5916) lr 1.5878e-03 eta 0:10:55
epoch [17/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.2183 (0.4998) lr 1.5878e-03 eta 0:09:28
epoch [17/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0833 (0.4966) lr 1.5878e-03 eta 0:08:58
epoch [17/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0343 (0.4864) lr 1.5878e-03 eta 0:08:42
epoch [17/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1886 (0.4745) lr 1.5878e-03 eta 0:08:33
epoch [17/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.4170 (0.4541) lr 1.5878e-03 eta 0:08:25
epoch [17/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1083 (0.4341) lr 1.5878e-03 eta 0:08:20
epoch [17/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.7676 (0.4205) lr 1.5878e-03 eta 0:08:15
epoch [17/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2703 (0.4085) lr 1.5878e-03 eta 0:08:12
epoch [17/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.4583 (0.3986) lr 1.5878e-03 eta 0:08:08
epoch [18/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1586 (0.3602) lr 1.5358e-03 eta 0:10:37
epoch [18/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.0829 (0.3483) lr 1.5358e-03 eta 0:09:11
epoch [18/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 1.4111 (0.3496) lr 1.5358e-03 eta 0:08:41
epoch [18/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0158 (0.3889) lr 1.5358e-03 eta 0:08:26
epoch [18/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.5425 (0.3928) lr 1.5358e-03 eta 0:08:16
epoch [18/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.6069 (0.3740) lr 1.5358e-03 eta 0:08:09
epoch [18/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.6514 (0.3898) lr 1.5358e-03 eta 0:08:04
epoch [18/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.8853 (0.3868) lr 1.5358e-03 eta 0:07:59
epoch [18/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1138 (0.3751) lr 1.5358e-03 eta 0:07:55
epoch [18/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.4529 (0.3754) lr 1.5358e-03 eta 0:07:52
epoch [19/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.3865 (0.3811) lr 1.4818e-03 eta 0:10:19
epoch [19/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.2542 (0.3641) lr 1.4818e-03 eta 0:08:55
epoch [19/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0967 (0.3337) lr 1.4818e-03 eta 0:08:27
epoch [19/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.2312 (0.3545) lr 1.4818e-03 eta 0:08:12
epoch [19/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0692 (0.3708) lr 1.4818e-03 eta 0:08:02
epoch [19/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.8276 (0.4014) lr 1.4818e-03 eta 0:07:55
epoch [19/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.9014 (0.3959) lr 1.4818e-03 eta 0:07:50
epoch [19/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0847 (0.3839) lr 1.4818e-03 eta 0:07:46
epoch [19/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5225 (0.3795) lr 1.4818e-03 eta 0:07:42
epoch [19/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.6592 (0.3735) lr 1.4818e-03 eta 0:07:38
epoch [20/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.9595 (0.4301) lr 1.4258e-03 eta 0:09:56
epoch [20/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.8232 (0.4203) lr 1.4258e-03 eta 0:08:36
epoch [20/50] batch [60/204] time 0.070 (0.078) data 0.001 (0.008) loss 0.2054 (0.4832) lr 1.4258e-03 eta 0:08:09
epoch [20/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4556 (0.4669) lr 1.4258e-03 eta 0:07:54
epoch [20/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.5688 (0.4987) lr 1.4258e-03 eta 0:07:45
epoch [20/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.8818 (0.4818) lr 1.4258e-03 eta 0:07:38
epoch [20/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.6274 (0.4682) lr 1.4258e-03 eta 0:07:33
epoch [20/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.0088 (0.4675) lr 1.4258e-03 eta 0:07:29
epoch [20/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4016 (0.4546) lr 1.4258e-03 eta 0:07:25
epoch [20/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.1835 (0.4407) lr 1.4258e-03 eta 0:07:22
epoch [21/50] batch [20/204] time 0.070 (0.094) data 0.000 (0.024) loss 0.6396 (0.3195) lr 1.3681e-03 eta 0:09:35
epoch [21/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.6797 (0.3095) lr 1.3681e-03 eta 0:08:19
epoch [21/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0731 (0.2894) lr 1.3681e-03 eta 0:07:52
epoch [21/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0849 (0.3011) lr 1.3681e-03 eta 0:07:39
epoch [21/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.4089 (0.3106) lr 1.3681e-03 eta 0:07:30
epoch [21/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1737 (0.3297) lr 1.3681e-03 eta 0:07:23
epoch [21/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.0489 (0.3591) lr 1.3681e-03 eta 0:07:18
epoch [21/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2495 (0.3689) lr 1.3681e-03 eta 0:07:14
epoch [21/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.7725 (0.3723) lr 1.3681e-03 eta 0:07:11
epoch [21/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.002) loss 0.1090 (0.3844) lr 1.3681e-03 eta 0:07:07
epoch [22/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1260 (0.3282) lr 1.3090e-03 eta 0:09:18
epoch [22/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.2659 (0.3700) lr 1.3090e-03 eta 0:08:03
epoch [22/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0615 (0.3345) lr 1.3090e-03 eta 0:07:37
epoch [22/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0330 (0.3316) lr 1.3090e-03 eta 0:07:24
epoch [22/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.5581 (0.3436) lr 1.3090e-03 eta 0:07:15
epoch [22/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0309 (0.3265) lr 1.3090e-03 eta 0:07:09
epoch [22/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0165 (0.3250) lr 1.3090e-03 eta 0:07:04
epoch [22/50] batch [160/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.0258 (0.3305) lr 1.3090e-03 eta 0:07:00
epoch [22/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1617 (0.3441) lr 1.3090e-03 eta 0:06:57
epoch [22/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.5508 (0.3463) lr 1.3090e-03 eta 0:06:54
epoch [23/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.2188 (0.3827) lr 1.2487e-03 eta 0:09:01
epoch [23/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 1.1172 (0.3733) lr 1.2487e-03 eta 0:07:48
epoch [23/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0211 (0.3839) lr 1.2487e-03 eta 0:07:22
epoch [23/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 1.0537 (0.3624) lr 1.2487e-03 eta 0:07:09
epoch [23/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2303 (0.3384) lr 1.2487e-03 eta 0:07:01
epoch [23/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0124 (0.3335) lr 1.2487e-03 eta 0:06:55
epoch [23/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.5068 (0.3450) lr 1.2487e-03 eta 0:06:50
epoch [23/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1037 (0.3383) lr 1.2487e-03 eta 0:06:46
epoch [23/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5757 (0.3414) lr 1.2487e-03 eta 0:06:42
epoch [23/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.1284 (0.3499) lr 1.2487e-03 eta 0:06:39
epoch [24/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.9199 (0.3223) lr 1.1874e-03 eta 0:08:40
epoch [24/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.0681 (0.2928) lr 1.1874e-03 eta 0:07:30
epoch [24/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0520 (0.2936) lr 1.1874e-03 eta 0:07:06
epoch [24/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.3831 (0.2817) lr 1.1874e-03 eta 0:06:53
epoch [24/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0412 (0.2747) lr 1.1874e-03 eta 0:06:45
epoch [24/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0906 (0.2771) lr 1.1874e-03 eta 0:06:39
epoch [24/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0198 (0.2882) lr 1.1874e-03 eta 0:06:35
epoch [24/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1268 (0.3117) lr 1.1874e-03 eta 0:06:31
epoch [24/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.3169 (0.3299) lr 1.1874e-03 eta 0:06:27
epoch [24/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.8389 (0.3257) lr 1.1874e-03 eta 0:06:24
epoch [25/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.8076 (0.3189) lr 1.1253e-03 eta 0:08:22
epoch [25/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0727 (0.3279) lr 1.1253e-03 eta 0:07:14
epoch [25/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0730 (0.3669) lr 1.1253e-03 eta 0:06:50
epoch [25/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0479 (0.3354) lr 1.1253e-03 eta 0:06:38
epoch [25/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.6157 (0.3523) lr 1.1253e-03 eta 0:06:30
epoch [25/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 1.1885 (0.3555) lr 1.1253e-03 eta 0:06:24
epoch [25/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1908 (0.3449) lr 1.1253e-03 eta 0:06:19
epoch [25/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1832 (0.3567) lr 1.1253e-03 eta 0:06:16
epoch [25/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.8081 (0.3493) lr 1.1253e-03 eta 0:06:12
epoch [25/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.0114 (0.3295) lr 1.1253e-03 eta 0:06:09
epoch [26/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.4844 (0.4860) lr 1.0628e-03 eta 0:08:03
epoch [26/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.1304 (0.3402) lr 1.0628e-03 eta 0:06:59
epoch [26/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.3049 (0.3196) lr 1.0628e-03 eta 0:06:36
epoch [26/50] batch [80/204] time 0.070 (0.077) data 0.000 (0.006) loss 0.0244 (0.3325) lr 1.0628e-03 eta 0:06:24
epoch [26/50] batch [100/204] time 0.071 (0.075) data 0.000 (0.005) loss 0.4309 (0.3421) lr 1.0628e-03 eta 0:06:17
epoch [26/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.1678 (0.3403) lr 1.0628e-03 eta 0:06:11
epoch [26/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 0.6797 (0.3323) lr 1.0628e-03 eta 0:06:07
epoch [26/50] batch [160/204] time 0.070 (0.074) data 0.000 (0.003) loss 0.1396 (0.3278) lr 1.0628e-03 eta 0:06:03
epoch [26/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0080 (0.3151) lr 1.0628e-03 eta 0:06:00
epoch [26/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0622 (0.3138) lr 1.0628e-03 eta 0:05:57
epoch [27/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.0547 (0.3689) lr 1.0000e-03 eta 0:07:42
epoch [27/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.5537 (0.3026) lr 1.0000e-03 eta 0:06:40
epoch [27/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.4170 (0.2603) lr 1.0000e-03 eta 0:06:18
epoch [27/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4963 (0.2678) lr 1.0000e-03 eta 0:06:07
epoch [27/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2218 (0.3036) lr 1.0000e-03 eta 0:05:59
epoch [27/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1810 (0.2996) lr 1.0000e-03 eta 0:05:54
epoch [27/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3213 (0.3106) lr 1.0000e-03 eta 0:05:49
epoch [27/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5005 (0.3144) lr 1.0000e-03 eta 0:05:46
epoch [27/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1178 (0.2977) lr 1.0000e-03 eta 0:05:43
epoch [27/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.7485 (0.2880) lr 1.0000e-03 eta 0:05:39
epoch [28/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1237 (0.1682) lr 9.3721e-04 eta 0:07:23
epoch [28/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.7974 (0.2312) lr 9.3721e-04 eta 0:06:23
epoch [28/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.8750 (0.2769) lr 9.3721e-04 eta 0:06:02
epoch [28/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.6719 (0.2956) lr 9.3721e-04 eta 0:05:51
epoch [28/50] batch [100/204] time 0.071 (0.075) data 0.000 (0.005) loss 0.1078 (0.2971) lr 9.3721e-04 eta 0:05:44
epoch [28/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0851 (0.3095) lr 9.3721e-04 eta 0:05:38
epoch [28/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.6367 (0.3051) lr 9.3721e-04 eta 0:05:34
epoch [28/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1326 (0.3173) lr 9.3721e-04 eta 0:05:31
epoch [28/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0558 (0.3021) lr 9.3721e-04 eta 0:05:27
epoch [28/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.1356 (0.3114) lr 9.3721e-04 eta 0:05:24
epoch [29/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.9761 (0.3092) lr 8.7467e-04 eta 0:07:03
epoch [29/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.1478 (0.3151) lr 8.7467e-04 eta 0:06:06
epoch [29/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.9243 (0.3199) lr 8.7467e-04 eta 0:05:46
epoch [29/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.5859 (0.3356) lr 8.7467e-04 eta 0:05:35
epoch [29/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0128 (0.3292) lr 8.7467e-04 eta 0:05:28
epoch [29/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1142 (0.3353) lr 8.7467e-04 eta 0:05:23
epoch [29/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.0237 (0.3143) lr 8.7467e-04 eta 0:05:19
epoch [29/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4695 (0.3315) lr 8.7467e-04 eta 0:05:15
epoch [29/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5391 (0.3183) lr 8.7467e-04 eta 0:05:12
epoch [29/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.0278 (0.3095) lr 8.7467e-04 eta 0:05:09
epoch [30/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.2720 (0.1923) lr 8.1262e-04 eta 0:06:43
epoch [30/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.1259 (0.2109) lr 8.1262e-04 eta 0:05:48
epoch [30/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0245 (0.2531) lr 8.1262e-04 eta 0:05:29
epoch [30/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.6875 (0.2519) lr 8.1262e-04 eta 0:05:19
epoch [30/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.3076 (0.2775) lr 8.1262e-04 eta 0:05:13
epoch [30/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 1.5254 (0.2689) lr 8.1262e-04 eta 0:05:08
epoch [30/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.2610 (0.2760) lr 8.1262e-04 eta 0:05:04
epoch [30/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4231 (0.2750) lr 8.1262e-04 eta 0:05:00
epoch [30/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.2236 (0.2892) lr 8.1262e-04 eta 0:04:58
epoch [30/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.0350 (0.3003) lr 8.1262e-04 eta 0:04:55
epoch [31/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 1.2627 (0.1997) lr 7.5131e-04 eta 0:06:24
epoch [31/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.6724 (0.2700) lr 7.5131e-04 eta 0:05:32
epoch [31/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0450 (0.2934) lr 7.5131e-04 eta 0:05:13
epoch [31/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.7314 (0.2717) lr 7.5131e-04 eta 0:05:04
epoch [31/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.9922 (0.2707) lr 7.5131e-04 eta 0:04:57
epoch [31/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.2181 (0.2598) lr 7.5131e-04 eta 0:04:53
epoch [31/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.0867 (0.2618) lr 7.5131e-04 eta 0:04:49
epoch [31/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.7549 (0.2517) lr 7.5131e-04 eta 0:04:46
epoch [31/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1631 (0.2644) lr 7.5131e-04 eta 0:04:43
epoch [31/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.0454 (0.2522) lr 7.5131e-04 eta 0:04:40
epoch [32/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1899 (0.1609) lr 6.9098e-04 eta 0:06:07
epoch [32/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.4143 (0.2531) lr 6.9098e-04 eta 0:05:17
epoch [32/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.0106 (0.3133) lr 6.9098e-04 eta 0:05:00
epoch [32/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 0.1132 (0.3059) lr 6.9098e-04 eta 0:04:50
epoch [32/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0233 (0.2988) lr 6.9098e-04 eta 0:04:44
epoch [32/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.0453 (0.3026) lr 6.9098e-04 eta 0:04:40
epoch [32/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1470 (0.2895) lr 6.9098e-04 eta 0:04:36
epoch [32/50] batch [160/204] time 0.070 (0.074) data 0.000 (0.003) loss 1.5098 (0.2835) lr 6.9098e-04 eta 0:04:33
epoch [32/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2166 (0.3013) lr 6.9098e-04 eta 0:04:30
epoch [32/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3643 (0.2964) lr 6.9098e-04 eta 0:04:27
epoch [33/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.0109 (0.1911) lr 6.3188e-04 eta 0:05:48
epoch [33/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.7656 (0.2684) lr 6.3188e-04 eta 0:05:00
epoch [33/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1686 (0.2759) lr 6.3188e-04 eta 0:04:43
epoch [33/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0109 (0.2768) lr 6.3188e-04 eta 0:04:33
epoch [33/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2544 (0.3284) lr 6.3188e-04 eta 0:04:27
epoch [33/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.4714 (0.3144) lr 6.3188e-04 eta 0:04:23
epoch [33/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.2756 (0.3021) lr 6.3188e-04 eta 0:04:19
epoch [33/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4644 (0.3032) lr 6.3188e-04 eta 0:04:16
epoch [33/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0701 (0.3036) lr 6.3188e-04 eta 0:04:13
epoch [33/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.0256 (0.3202) lr 6.3188e-04 eta 0:04:11
epoch [34/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.0299 (0.2302) lr 5.7422e-04 eta 0:05:28
epoch [34/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.1388 (0.2392) lr 5.7422e-04 eta 0:04:43
epoch [34/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0414 (0.2630) lr 5.7422e-04 eta 0:04:27
epoch [34/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.1779 (0.2451) lr 5.7422e-04 eta 0:04:18
epoch [34/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.3735 (0.2492) lr 5.7422e-04 eta 0:04:12
epoch [34/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0253 (0.2418) lr 5.7422e-04 eta 0:04:08
epoch [34/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0994 (0.2411) lr 5.7422e-04 eta 0:04:05
epoch [34/50] batch [160/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.1014 (0.2549) lr 5.7422e-04 eta 0:04:02
epoch [34/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0804 (0.2553) lr 5.7422e-04 eta 0:03:59
epoch [34/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0251 (0.2543) lr 5.7422e-04 eta 0:03:57
epoch [35/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.1438 (0.4197) lr 5.1825e-04 eta 0:05:08
epoch [35/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.2439 (0.4314) lr 5.1825e-04 eta 0:04:25
epoch [35/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.0681 (0.3849) lr 5.1825e-04 eta 0:04:10
epoch [35/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0265 (0.3361) lr 5.1825e-04 eta 0:04:02
epoch [35/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0404 (0.3100) lr 5.1825e-04 eta 0:03:57
epoch [35/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1038 (0.3222) lr 5.1825e-04 eta 0:03:53
epoch [35/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0415 (0.3163) lr 5.1825e-04 eta 0:03:49
epoch [35/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5171 (0.3128) lr 5.1825e-04 eta 0:03:47
epoch [35/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0948 (0.3104) lr 5.1825e-04 eta 0:03:44
epoch [35/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.6006 (0.3100) lr 5.1825e-04 eta 0:03:42
epoch [36/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.6997 (0.2604) lr 4.6417e-04 eta 0:04:48
epoch [36/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.2854 (0.3677) lr 4.6417e-04 eta 0:04:09
epoch [36/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1107 (0.3322) lr 4.6417e-04 eta 0:03:54
epoch [36/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.4456 (0.3341) lr 4.6417e-04 eta 0:03:46
epoch [36/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1179 (0.3084) lr 4.6417e-04 eta 0:03:41
epoch [36/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1510 (0.3062) lr 4.6417e-04 eta 0:03:37
epoch [36/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.1469 (0.3018) lr 4.6417e-04 eta 0:03:34
epoch [36/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0327 (0.2910) lr 4.6417e-04 eta 0:03:31
epoch [36/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1331 (0.2991) lr 4.6417e-04 eta 0:03:29
epoch [36/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.5083 (0.2997) lr 4.6417e-04 eta 0:03:26
epoch [37/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.0690 (0.2797) lr 4.1221e-04 eta 0:04:28
epoch [37/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 2.0566 (0.3644) lr 4.1221e-04 eta 0:03:51
epoch [37/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2284 (0.3294) lr 4.1221e-04 eta 0:03:38
epoch [37/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0323 (0.3265) lr 4.1221e-04 eta 0:03:31
epoch [37/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2308 (0.3274) lr 4.1221e-04 eta 0:03:26
epoch [37/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3376 (0.3018) lr 4.1221e-04 eta 0:03:22
epoch [37/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0207 (0.3007) lr 4.1221e-04 eta 0:03:19
epoch [37/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 1.3320 (0.3061) lr 4.1221e-04 eta 0:03:17
epoch [37/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4053 (0.2936) lr 4.1221e-04 eta 0:03:14
epoch [37/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.6113 (0.2895) lr 4.1221e-04 eta 0:03:12
epoch [38/50] batch [20/204] time 0.071 (0.096) data 0.000 (0.024) loss 0.0286 (0.3094) lr 3.6258e-04 eta 0:04:12
epoch [38/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0114 (0.2716) lr 3.6258e-04 eta 0:03:37
epoch [38/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.9907 (0.2702) lr 3.6258e-04 eta 0:03:24
epoch [38/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 0.3464 (0.2737) lr 3.6258e-04 eta 0:03:17
epoch [38/50] batch [100/204] time 0.071 (0.076) data 0.000 (0.005) loss 0.9912 (0.2832) lr 3.6258e-04 eta 0:03:13
epoch [38/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.1038 (0.2724) lr 3.6258e-04 eta 0:03:09
epoch [38/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 1.5127 (0.3063) lr 3.6258e-04 eta 0:03:06
epoch [38/50] batch [160/204] time 0.071 (0.074) data 0.000 (0.003) loss 0.5391 (0.3033) lr 3.6258e-04 eta 0:03:03
epoch [38/50] batch [180/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.2905 (0.3236) lr 3.6258e-04 eta 0:03:01
epoch [38/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0267 (0.3222) lr 3.6258e-04 eta 0:02:59
epoch [39/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.5693 (0.3017) lr 3.1545e-04 eta 0:03:51
epoch [39/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.4741 (0.2993) lr 3.1545e-04 eta 0:03:18
epoch [39/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1194 (0.2899) lr 3.1545e-04 eta 0:03:07
epoch [39/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0038 (0.2387) lr 3.1545e-04 eta 0:03:00
epoch [39/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0511 (0.2391) lr 3.1545e-04 eta 0:02:56
epoch [39/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0104 (0.2425) lr 3.1545e-04 eta 0:02:52
epoch [39/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1935 (0.2525) lr 3.1545e-04 eta 0:02:50
epoch [39/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0151 (0.2477) lr 3.1545e-04 eta 0:02:47
epoch [39/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0353 (0.2413) lr 3.1545e-04 eta 0:02:45
epoch [39/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.1682 (0.2542) lr 3.1545e-04 eta 0:02:43
epoch [40/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.2478 (0.1814) lr 2.7103e-04 eta 0:03:31
epoch [40/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.0410 (0.2592) lr 2.7103e-04 eta 0:03:01
epoch [40/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1504 (0.2662) lr 2.7103e-04 eta 0:02:51
epoch [40/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0981 (0.2739) lr 2.7103e-04 eta 0:02:45
epoch [40/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.5459 (0.2883) lr 2.7103e-04 eta 0:02:40
epoch [40/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1411 (0.3103) lr 2.7103e-04 eta 0:02:37
epoch [40/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0852 (0.2952) lr 2.7103e-04 eta 0:02:34
epoch [40/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0260 (0.2886) lr 2.7103e-04 eta 0:02:32
epoch [40/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2932 (0.2819) lr 2.7103e-04 eta 0:02:30
epoch [40/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.0050 (0.2779) lr 2.7103e-04 eta 0:02:28
epoch [41/50] batch [20/204] time 0.070 (0.096) data 0.000 (0.025) loss 0.4026 (0.4066) lr 2.2949e-04 eta 0:03:13
epoch [41/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.013) loss 0.0534 (0.2765) lr 2.2949e-04 eta 0:02:46
epoch [41/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.0181 (0.2288) lr 2.2949e-04 eta 0:02:35
epoch [41/50] batch [80/204] time 0.071 (0.077) data 0.000 (0.006) loss 1.1328 (0.2578) lr 2.2949e-04 eta 0:02:30
epoch [41/50] batch [100/204] time 0.071 (0.075) data 0.000 (0.005) loss 0.0360 (0.2544) lr 2.2949e-04 eta 0:02:26
epoch [41/50] batch [120/204] time 0.070 (0.075) data 0.000 (0.004) loss 0.1882 (0.2768) lr 2.2949e-04 eta 0:02:23
epoch [41/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0033 (0.2696) lr 2.2949e-04 eta 0:02:20
epoch [41/50] batch [160/204] time 0.070 (0.074) data 0.000 (0.003) loss 0.0267 (0.2701) lr 2.2949e-04 eta 0:02:18
epoch [41/50] batch [180/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.0577 (0.2729) lr 2.2949e-04 eta 0:02:16
epoch [41/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.7217 (0.2663) lr 2.2949e-04 eta 0:02:14
epoch [42/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.3674 (0.1378) lr 1.9098e-04 eta 0:02:53
epoch [42/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0767 (0.1996) lr 1.9098e-04 eta 0:02:28
epoch [42/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2778 (0.1954) lr 1.9098e-04 eta 0:02:19
epoch [42/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0201 (0.2076) lr 1.9098e-04 eta 0:02:14
epoch [42/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.2351 (0.2245) lr 1.9098e-04 eta 0:02:10
epoch [42/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0238 (0.2246) lr 1.9098e-04 eta 0:02:07
epoch [42/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.3711 (0.2130) lr 1.9098e-04 eta 0:02:05
epoch [42/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.3979 (0.2186) lr 1.9098e-04 eta 0:02:02
epoch [42/50] batch [180/204] time 0.072 (0.073) data 0.000 (0.003) loss 0.0032 (0.2201) lr 1.9098e-04 eta 0:02:00
epoch [42/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.3918 (0.2144) lr 1.9098e-04 eta 0:01:58
epoch [43/50] batch [20/204] time 0.070 (0.096) data 0.000 (0.025) loss 0.0517 (0.3695) lr 1.5567e-04 eta 0:02:33
epoch [43/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0304 (0.2693) lr 1.5567e-04 eta 0:02:11
epoch [43/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.0996 (0.2150) lr 1.5567e-04 eta 0:02:03
epoch [43/50] batch [80/204] time 0.070 (0.077) data 0.000 (0.006) loss 0.6763 (0.2199) lr 1.5567e-04 eta 0:01:58
epoch [43/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0195 (0.2325) lr 1.5567e-04 eta 0:01:55
epoch [43/50] batch [120/204] time 0.070 (0.075) data 0.000 (0.004) loss 0.0164 (0.2354) lr 1.5567e-04 eta 0:01:52
epoch [43/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.1193 (0.2319) lr 1.5567e-04 eta 0:01:50
epoch [43/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.5513 (0.2390) lr 1.5567e-04 eta 0:01:48
epoch [43/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0098 (0.2440) lr 1.5567e-04 eta 0:01:46
epoch [43/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.2329 (0.2371) lr 1.5567e-04 eta 0:01:44
epoch [44/50] batch [20/204] time 0.071 (0.096) data 0.000 (0.025) loss 0.2286 (0.2322) lr 1.2369e-04 eta 0:02:15
epoch [44/50] batch [40/204] time 0.071 (0.083) data 0.000 (0.012) loss 1.2812 (0.2433) lr 1.2369e-04 eta 0:01:55
epoch [44/50] batch [60/204] time 0.071 (0.079) data 0.000 (0.008) loss 0.4221 (0.2227) lr 1.2369e-04 eta 0:01:48
epoch [44/50] batch [80/204] time 0.070 (0.077) data 0.000 (0.006) loss 0.1476 (0.2298) lr 1.2369e-04 eta 0:01:43
epoch [44/50] batch [100/204] time 0.071 (0.076) data 0.000 (0.005) loss 0.1602 (0.2175) lr 1.2369e-04 eta 0:01:40
epoch [44/50] batch [120/204] time 0.071 (0.075) data 0.000 (0.004) loss 0.0485 (0.2325) lr 1.2369e-04 eta 0:01:37
epoch [44/50] batch [140/204] time 0.071 (0.074) data 0.000 (0.004) loss 0.0947 (0.2238) lr 1.2369e-04 eta 0:01:35
epoch [44/50] batch [160/204] time 0.070 (0.074) data 0.000 (0.003) loss 1.0752 (0.2277) lr 1.2369e-04 eta 0:01:33
epoch [44/50] batch [180/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.0287 (0.2461) lr 1.2369e-04 eta 0:01:31
epoch [44/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.2435 (0.2564) lr 1.2369e-04 eta 0:01:29
epoch [45/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.9419 (0.2971) lr 9.5173e-05 eta 0:01:54
epoch [45/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.0748 (0.2248) lr 9.5173e-05 eta 0:01:37
epoch [45/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.6641 (0.2373) lr 9.5173e-05 eta 0:01:31
epoch [45/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.5459 (0.2758) lr 9.5173e-05 eta 0:01:27
epoch [45/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.1472 (0.2643) lr 9.5173e-05 eta 0:01:24
epoch [45/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0447 (0.2683) lr 9.5173e-05 eta 0:01:21
epoch [45/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.0240 (0.2643) lr 9.5173e-05 eta 0:01:19
epoch [45/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1323 (0.2737) lr 9.5173e-05 eta 0:01:17
epoch [45/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1632 (0.2804) lr 9.5173e-05 eta 0:01:15
epoch [45/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.0140 (0.2710) lr 9.5173e-05 eta 0:01:13
epoch [46/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.8262 (0.2783) lr 7.0224e-05 eta 0:01:35
epoch [46/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.2039 (0.2726) lr 7.0224e-05 eta 0:01:21
epoch [46/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.0371 (0.2241) lr 7.0224e-05 eta 0:01:15
epoch [46/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0340 (0.2212) lr 7.0224e-05 eta 0:01:11
epoch [46/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.3223 (0.2607) lr 7.0224e-05 eta 0:01:09
epoch [46/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0273 (0.2571) lr 7.0224e-05 eta 0:01:07
epoch [46/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0485 (0.2493) lr 7.0224e-05 eta 0:01:05
epoch [46/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1792 (0.2430) lr 7.0224e-05 eta 0:01:03
epoch [46/50] batch [180/204] time 0.071 (0.073) data 0.000 (0.003) loss 0.1132 (0.2415) lr 7.0224e-05 eta 0:01:01
epoch [46/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.1300 (0.2587) lr 7.0224e-05 eta 0:00:59
epoch [47/50] batch [20/204] time 0.069 (0.094) data 0.000 (0.024) loss 0.2351 (0.3244) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.0850 (0.3113) lr 4.8943e-05 eta 0:01:03
epoch [47/50] batch [60/204] time 0.070 (0.078) data 0.001 (0.008) loss 0.0514 (0.2898) lr 4.8943e-05 eta 0:00:58
epoch [47/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0191 (0.2706) lr 4.8943e-05 eta 0:00:55
epoch [47/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0426 (0.2854) lr 4.8943e-05 eta 0:00:53
epoch [47/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.5347 (0.2935) lr 4.8943e-05 eta 0:00:51
epoch [47/50] batch [140/204] time 0.071 (0.073) data 0.001 (0.004) loss 0.0473 (0.3064) lr 4.8943e-05 eta 0:00:49
epoch [47/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.3345 (0.3029) lr 4.8943e-05 eta 0:00:47
epoch [47/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4980 (0.2922) lr 4.8943e-05 eta 0:00:46
epoch [47/50] batch [200/204] time 0.069 (0.072) data 0.000 (0.003) loss 0.2549 (0.2783) lr 4.8943e-05 eta 0:00:44
epoch [48/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.024) loss 0.1015 (0.3271) lr 3.1417e-05 eta 0:00:56
epoch [48/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.0194 (0.2607) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.2612 (0.2686) lr 3.1417e-05 eta 0:00:43
epoch [48/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0097 (0.2873) lr 3.1417e-05 eta 0:00:40
epoch [48/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0546 (0.2673) lr 3.1417e-05 eta 0:00:38
epoch [48/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0200 (0.2612) lr 3.1417e-05 eta 0:00:36
epoch [48/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0195 (0.2739) lr 3.1417e-05 eta 0:00:34
epoch [48/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1151 (0.2734) lr 3.1417e-05 eta 0:00:33
epoch [48/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.1151 (0.2637) lr 3.1417e-05 eta 0:00:31
epoch [48/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0278 (0.2596) lr 3.1417e-05 eta 0:00:29
epoch [49/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.3215 (0.1995) lr 1.7713e-05 eta 0:00:37
epoch [49/50] batch [40/204] time 0.070 (0.083) data 0.000 (0.012) loss 0.6587 (0.2236) lr 1.7713e-05 eta 0:00:30
epoch [49/50] batch [60/204] time 0.070 (0.079) data 0.000 (0.008) loss 0.1768 (0.2604) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.0891 (0.2866) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0886 (0.2639) lr 1.7713e-05 eta 0:00:23
epoch [49/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0314 (0.2476) lr 1.7713e-05 eta 0:00:21
epoch [49/50] batch [140/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0482 (0.2546) lr 1.7713e-05 eta 0:00:19
epoch [49/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.0250 (0.2672) lr 1.7713e-05 eta 0:00:18
epoch [49/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4919 (0.2692) lr 1.7713e-05 eta 0:00:16
epoch [49/50] batch [200/204] time 0.069 (0.073) data 0.000 (0.003) loss 0.0612 (0.2584) lr 1.7713e-05 eta 0:00:15
epoch [50/50] batch [20/204] time 0.070 (0.095) data 0.000 (0.025) loss 0.2695 (0.1595) lr 7.8853e-06 eta 0:00:17
epoch [50/50] batch [40/204] time 0.070 (0.082) data 0.000 (0.012) loss 0.7173 (0.2031) lr 7.8853e-06 eta 0:00:13
epoch [50/50] batch [60/204] time 0.070 (0.078) data 0.000 (0.008) loss 0.1525 (0.2285) lr 7.8853e-06 eta 0:00:11
epoch [50/50] batch [80/204] time 0.070 (0.076) data 0.000 (0.006) loss 0.1122 (0.2031) lr 7.8853e-06 eta 0:00:09
epoch [50/50] batch [100/204] time 0.070 (0.075) data 0.000 (0.005) loss 0.0164 (0.2002) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [120/204] time 0.070 (0.074) data 0.000 (0.004) loss 0.0699 (0.2083) lr 7.8853e-06 eta 0:00:06
epoch [50/50] batch [140/204] time 0.070 (0.073) data 0.000 (0.004) loss 0.1232 (0.2149) lr 7.8853e-06 eta 0:00:04
epoch [50/50] batch [160/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.2715 (0.2300) lr 7.8853e-06 eta 0:00:03
epoch [50/50] batch [180/204] time 0.070 (0.073) data 0.000 (0.003) loss 0.4263 (0.2456) lr 7.8853e-06 eta 0:00:01
epoch [50/50] batch [200/204] time 0.068 (0.072) data 0.000 (0.003) loss 0.6758 (0.2449) lr 7.8853e-06 eta 0:00:00
Checkpoint saved to output/base2new/train_base/oxford_flowers/shots_16/CoCoOp/vit_b16_c4_ep50_bs4/seed3/prompt_learner/model.pth.tar-50
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,241
* correct: 1,200
* accuracy: 96.70%
* error: 3.30%
* macro_f1: 96.36%
Elapsed: 0:12:39
