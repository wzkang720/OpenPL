***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO/main_K24_ep50_batch4.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo/base2new/train_base/caltech101/shots_16/RPO/main_K24_ep50_batch4/seed1
resume: 
root: /mnt/hdd/DATA
seed: 1
source_domains: None
target_domains: None
trainer: RPO
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /mnt/hdd/DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.02
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo/base2new/train_base/caltech101/shots_16/RPO/main_K24_ep50_batch4/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO
  RPO:
    CTX_INIT: X X X X
    K: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.2.2+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Debian GNU/Linux 12 (bookworm) (x86_64)
GCC version: (Debian 12.2.0-14) 12.2.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.36

Python version: 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (64-bit runtime)
Python platform: Linux-6.5.13-3-pve-x86_64-with-glibc2.36
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: NVIDIA A800 80GB PCIe
GPU 1: NVIDIA A800 80GB PCIe

Nvidia driver version: 525.147.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Address sizes:                      46 bits physical, 57 bits virtual
Byte Order:                         Little Endian
CPU(s):                             64
On-line CPU(s) list:                0-24,26-32
Off-line CPU(s) list:               25,33-63
Vendor ID:                          GenuineIntel
Model name:                         Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz
CPU family:                         6
Model:                              106
Thread(s) per core:                 2
Core(s) per socket:                 16
Socket(s):                          2
Stepping:                           6
CPU(s) scaling MHz:                 98%
CPU max MHz:                        3500.0000
CPU min MHz:                        800.0000
BogoMIPS:                           5800.00
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 invpcid_single intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local split_lock_detect wbnoinvd dtherm ida arat pln pts vnmi avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq la57 rdpid fsrm md_clear pconfig flush_l1d arch_capabilities
Virtualization:                     VT-x
L1d cache:                          1.5 MiB (32 instances)
L1i cache:                          1 MiB (32 instances)
L2 cache:                           40 MiB (32 instances)
L3 cache:                           48 MiB (2 instances)
NUMA node(s):                       2
NUMA node0 CPU(s):                  0-15,32-47
NUMA node1 CPU(s):                  16-31,48-63
Vulnerability Gather data sampling: Vulnerable: No microcode
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Mitigation; Clear CPU buffers; SMT vulnerable
Vulnerability Retbleed:             Not affected
Vulnerability Spec rstack overflow: Not affected
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Enhanced / Automatic IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected

Versions of relevant libraries:
[pip3] flake8==3.7.9
[pip3] numpy==1.26.4
[pip3] torch==2.2.2
[pip3] torchaudio==2.2.2
[pip3] torchvision==0.17.2
[pip3] triton==2.2.0
[conda] Could not collect
        Pillow (10.3.0)

Loading trainer: RPO
Loading dataset: Caltech101
Reading split from /mnt/hdd/DATA/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /mnt/hdd/DATA/caltech-101/split_fewshot/shot_16_shuffled-seed_1.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      200
# test     1,287
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo/base2new/train_base/caltech101/shots_16/RPO/main_K24_ep50_batch4/seed1/tensorboard)
epoch [1/50] batch [20/200] time 0.273 (0.405) data 0.000 (0.028) loss 0.7049 (0.5767) lr 1.0000e-05 eta 1:07:20
epoch [1/50] batch [40/200] time 0.259 (0.337) data 0.000 (0.014) loss 0.1499 (0.6165) lr 1.0000e-05 eta 0:55:55
epoch [1/50] batch [60/200] time 0.258 (0.311) data 0.000 (0.009) loss 0.9859 (0.6619) lr 1.0000e-05 eta 0:51:34
epoch [1/50] batch [80/200] time 0.260 (0.299) data 0.000 (0.007) loss 0.2851 (0.6231) lr 1.0000e-05 eta 0:49:21
epoch [1/50] batch [100/200] time 0.260 (0.292) data 0.000 (0.006) loss 0.1545 (0.6086) lr 1.0000e-05 eta 0:48:11
epoch [1/50] batch [120/200] time 0.259 (0.287) data 0.000 (0.005) loss 1.6440 (0.6318) lr 1.0000e-05 eta 0:47:12
epoch [1/50] batch [140/200] time 0.259 (0.283) data 0.000 (0.004) loss 0.0012 (0.6041) lr 1.0000e-05 eta 0:46:30
epoch [1/50] batch [160/200] time 0.258 (0.280) data 0.000 (0.004) loss 0.8393 (0.6353) lr 1.0000e-05 eta 0:45:56
epoch [1/50] batch [180/200] time 0.262 (0.279) data 0.000 (0.003) loss 0.9148 (0.6260) lr 1.0000e-05 eta 0:45:42
epoch [1/50] batch [200/200] time 0.258 (0.277) data 0.000 (0.003) loss 0.3348 (0.6342) lr 2.0000e-02 eta 0:45:15
epoch [2/50] batch [20/200] time 0.265 (0.287) data 0.000 (0.023) loss 0.8648 (0.4286) lr 2.0000e-02 eta 0:46:43
epoch [2/50] batch [40/200] time 0.260 (0.275) data 0.000 (0.011) loss 0.1979 (0.4291) lr 2.0000e-02 eta 0:44:43
epoch [2/50] batch [60/200] time 0.264 (0.272) data 0.000 (0.008) loss 0.6398 (0.4346) lr 2.0000e-02 eta 0:44:04
epoch [2/50] batch [80/200] time 0.258 (0.269) data 0.000 (0.006) loss 0.0118 (0.4512) lr 2.0000e-02 eta 0:43:32
epoch [2/50] batch [100/200] time 0.259 (0.267) data 0.000 (0.005) loss 0.6447 (0.4649) lr 2.0000e-02 eta 0:43:10
epoch [2/50] batch [120/200] time 0.259 (0.266) data 0.000 (0.004) loss 0.1398 (0.4408) lr 2.0000e-02 eta 0:42:56
epoch [2/50] batch [140/200] time 0.259 (0.266) data 0.000 (0.003) loss 0.0233 (0.4104) lr 2.0000e-02 eta 0:42:47
epoch [2/50] batch [160/200] time 0.260 (0.265) data 0.000 (0.003) loss 0.1109 (0.4419) lr 2.0000e-02 eta 0:42:35
epoch [2/50] batch [180/200] time 0.260 (0.265) data 0.000 (0.003) loss 0.0030 (0.4280) lr 2.0000e-02 eta 0:42:25
epoch [2/50] batch [200/200] time 0.257 (0.264) data 0.000 (0.002) loss 0.1211 (0.4118) lr 1.9980e-02 eta 0:42:14
epoch [3/50] batch [20/200] time 0.258 (0.288) data 0.000 (0.023) loss 0.3855 (0.5734) lr 1.9980e-02 eta 0:45:58
epoch [3/50] batch [40/200] time 0.259 (0.273) data 0.000 (0.012) loss 0.2745 (0.5549) lr 1.9980e-02 eta 0:43:30
epoch [3/50] batch [60/200] time 0.263 (0.268) data 0.001 (0.008) loss 0.1102 (0.4686) lr 1.9980e-02 eta 0:42:41
epoch [3/50] batch [80/200] time 0.259 (0.266) data 0.000 (0.006) loss 0.5637 (0.4775) lr 1.9980e-02 eta 0:42:12
epoch [3/50] batch [100/200] time 0.260 (0.266) data 0.000 (0.005) loss 1.1587 (0.4472) lr 1.9980e-02 eta 0:42:07
epoch [3/50] batch [120/200] time 0.263 (0.265) data 0.000 (0.004) loss 0.0376 (0.4729) lr 1.9980e-02 eta 0:41:52
epoch [3/50] batch [140/200] time 0.259 (0.264) data 0.000 (0.004) loss 0.0030 (0.4763) lr 1.9980e-02 eta 0:41:38
epoch [3/50] batch [160/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.2041 (0.4650) lr 1.9980e-02 eta 0:41:30
epoch [3/50] batch [180/200] time 0.259 (0.264) data 0.000 (0.003) loss 0.3381 (0.4726) lr 1.9980e-02 eta 0:41:26
epoch [3/50] batch [200/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.7291 (0.4771) lr 1.9921e-02 eta 0:41:17
epoch [4/50] batch [20/200] time 0.281 (0.299) data 0.000 (0.024) loss 0.3357 (0.4924) lr 1.9921e-02 eta 0:46:45
epoch [4/50] batch [40/200] time 0.264 (0.284) data 0.000 (0.012) loss 0.8016 (0.5241) lr 1.9921e-02 eta 0:44:13
epoch [4/50] batch [60/200] time 0.280 (0.281) data 0.000 (0.008) loss 0.9351 (0.5131) lr 1.9921e-02 eta 0:43:46
epoch [4/50] batch [80/200] time 0.274 (0.280) data 0.000 (0.006) loss 0.8583 (0.5152) lr 1.9921e-02 eta 0:43:26
epoch [4/50] batch [100/200] time 0.258 (0.277) data 0.000 (0.005) loss 0.6600 (0.5036) lr 1.9921e-02 eta 0:43:00
epoch [4/50] batch [120/200] time 0.259 (0.275) data 0.000 (0.004) loss 0.5598 (0.5016) lr 1.9921e-02 eta 0:42:36
epoch [4/50] batch [140/200] time 0.258 (0.273) data 0.000 (0.004) loss 0.4164 (0.4856) lr 1.9921e-02 eta 0:42:10
epoch [4/50] batch [160/200] time 0.258 (0.272) data 0.000 (0.003) loss 0.0035 (0.4838) lr 1.9921e-02 eta 0:41:49
epoch [4/50] batch [180/200] time 0.261 (0.271) data 0.000 (0.003) loss 0.4102 (0.4971) lr 1.9921e-02 eta 0:41:35
epoch [4/50] batch [200/200] time 0.273 (0.271) data 0.000 (0.003) loss 0.0479 (0.4782) lr 1.9823e-02 eta 0:41:32
epoch [5/50] batch [20/200] time 0.273 (0.292) data 0.000 (0.024) loss 0.1478 (0.5066) lr 1.9823e-02 eta 0:44:40
epoch [5/50] batch [40/200] time 0.259 (0.280) data 0.000 (0.012) loss 1.2133 (0.4879) lr 1.9823e-02 eta 0:42:44
epoch [5/50] batch [60/200] time 0.260 (0.273) data 0.000 (0.008) loss 0.3167 (0.4373) lr 1.9823e-02 eta 0:41:36
epoch [5/50] batch [80/200] time 0.263 (0.271) data 0.000 (0.006) loss 1.1474 (0.4577) lr 1.9823e-02 eta 0:41:11
epoch [5/50] batch [100/200] time 0.258 (0.269) data 0.000 (0.005) loss 0.5071 (0.4636) lr 1.9823e-02 eta 0:40:44
epoch [5/50] batch [120/200] time 0.258 (0.267) data 0.000 (0.004) loss 0.0415 (0.4439) lr 1.9823e-02 eta 0:40:25
epoch [5/50] batch [140/200] time 0.271 (0.266) data 0.000 (0.004) loss 0.5148 (0.4112) lr 1.9823e-02 eta 0:40:12
epoch [5/50] batch [160/200] time 0.262 (0.266) data 0.000 (0.003) loss 0.0025 (0.4262) lr 1.9823e-02 eta 0:40:04
epoch [5/50] batch [180/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.8451 (0.4475) lr 1.9823e-02 eta 0:39:52
epoch [5/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.0817 (0.4482) lr 1.9686e-02 eta 0:39:40
epoch [6/50] batch [20/200] time 0.258 (0.288) data 0.000 (0.024) loss 0.1287 (0.3795) lr 1.9686e-02 eta 0:43:06
epoch [6/50] batch [40/200] time 0.258 (0.277) data 0.000 (0.012) loss 0.0457 (0.3303) lr 1.9686e-02 eta 0:41:21
epoch [6/50] batch [60/200] time 0.257 (0.271) data 0.000 (0.008) loss 0.2933 (0.3653) lr 1.9686e-02 eta 0:40:20
epoch [6/50] batch [80/200] time 0.272 (0.269) data 0.000 (0.006) loss 0.0044 (0.3661) lr 1.9686e-02 eta 0:39:57
epoch [6/50] batch [100/200] time 0.258 (0.268) data 0.000 (0.005) loss 0.9087 (0.3685) lr 1.9686e-02 eta 0:39:42
epoch [6/50] batch [120/200] time 0.260 (0.266) data 0.000 (0.004) loss 1.0320 (0.4081) lr 1.9686e-02 eta 0:39:24
epoch [6/50] batch [140/200] time 0.259 (0.265) data 0.000 (0.004) loss 1.0419 (0.4158) lr 1.9686e-02 eta 0:39:10
epoch [6/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.7052 (0.4208) lr 1.9686e-02 eta 0:38:58
epoch [6/50] batch [180/200] time 0.262 (0.265) data 0.000 (0.003) loss 0.1630 (0.4214) lr 1.9686e-02 eta 0:38:54
epoch [6/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.5462 (0.4387) lr 1.9511e-02 eta 0:38:42
epoch [7/50] batch [20/200] time 0.257 (0.283) data 0.000 (0.023) loss 0.4152 (0.3849) lr 1.9511e-02 eta 0:41:21
epoch [7/50] batch [40/200] time 0.258 (0.271) data 0.000 (0.012) loss 0.0321 (0.4224) lr 1.9511e-02 eta 0:39:31
epoch [7/50] batch [60/200] time 0.272 (0.272) data 0.001 (0.008) loss 0.9945 (0.4232) lr 1.9511e-02 eta 0:39:35
epoch [7/50] batch [80/200] time 0.274 (0.272) data 0.000 (0.006) loss 0.0314 (0.4382) lr 1.9511e-02 eta 0:39:32
epoch [7/50] batch [100/200] time 0.272 (0.272) data 0.000 (0.005) loss 0.1532 (0.4070) lr 1.9511e-02 eta 0:39:30
epoch [7/50] batch [120/200] time 0.272 (0.273) data 0.000 (0.004) loss 0.0210 (0.4102) lr 1.9511e-02 eta 0:39:26
epoch [7/50] batch [140/200] time 0.259 (0.272) data 0.000 (0.003) loss 0.0052 (0.4146) lr 1.9511e-02 eta 0:39:19
epoch [7/50] batch [160/200] time 0.260 (0.272) data 0.000 (0.003) loss 0.2877 (0.4228) lr 1.9511e-02 eta 0:39:06
epoch [7/50] batch [180/200] time 0.258 (0.270) data 0.000 (0.003) loss 0.1562 (0.4224) lr 1.9511e-02 eta 0:38:49
epoch [7/50] batch [200/200] time 0.256 (0.269) data 0.000 (0.002) loss 0.6770 (0.4332) lr 1.9298e-02 eta 0:38:31
epoch [8/50] batch [20/200] time 0.258 (0.290) data 0.000 (0.023) loss 0.0320 (0.5946) lr 1.9298e-02 eta 0:41:24
epoch [8/50] batch [40/200] time 0.258 (0.275) data 0.000 (0.012) loss 0.2609 (0.5860) lr 1.9298e-02 eta 0:39:16
epoch [8/50] batch [60/200] time 0.258 (0.270) data 0.000 (0.008) loss 0.0103 (0.5412) lr 1.9298e-02 eta 0:38:22
epoch [8/50] batch [80/200] time 0.274 (0.268) data 0.000 (0.006) loss 0.0155 (0.4689) lr 1.9298e-02 eta 0:38:03
epoch [8/50] batch [100/200] time 0.262 (0.269) data 0.000 (0.005) loss 1.1024 (0.4758) lr 1.9298e-02 eta 0:38:10
epoch [8/50] batch [120/200] time 0.258 (0.269) data 0.000 (0.004) loss 1.1389 (0.4774) lr 1.9298e-02 eta 0:38:02
epoch [8/50] batch [140/200] time 0.258 (0.268) data 0.000 (0.003) loss 1.3972 (0.4632) lr 1.9298e-02 eta 0:37:44
epoch [8/50] batch [160/200] time 0.257 (0.267) data 0.000 (0.003) loss 0.0164 (0.4762) lr 1.9298e-02 eta 0:37:31
epoch [8/50] batch [180/200] time 0.266 (0.266) data 0.000 (0.003) loss 0.0277 (0.4575) lr 1.9298e-02 eta 0:37:22
epoch [8/50] batch [200/200] time 0.257 (0.266) data 0.000 (0.002) loss 0.2744 (0.4564) lr 1.9048e-02 eta 0:37:10
epoch [9/50] batch [20/200] time 0.272 (0.297) data 0.000 (0.024) loss 0.1673 (0.2813) lr 1.9048e-02 eta 0:41:29
epoch [9/50] batch [40/200] time 0.271 (0.285) data 0.000 (0.012) loss 0.5954 (0.4267) lr 1.9048e-02 eta 0:39:39
epoch [9/50] batch [60/200] time 0.259 (0.278) data 0.000 (0.008) loss 0.0334 (0.4018) lr 1.9048e-02 eta 0:38:41
epoch [9/50] batch [80/200] time 0.257 (0.273) data 0.000 (0.006) loss 0.0706 (0.4510) lr 1.9048e-02 eta 0:37:53
epoch [9/50] batch [100/200] time 0.258 (0.271) data 0.000 (0.005) loss 0.4503 (0.4432) lr 1.9048e-02 eta 0:37:25
epoch [9/50] batch [120/200] time 0.257 (0.269) data 0.000 (0.004) loss 0.3110 (0.4383) lr 1.9048e-02 eta 0:37:08
epoch [9/50] batch [140/200] time 0.258 (0.268) data 0.000 (0.004) loss 0.0175 (0.4206) lr 1.9048e-02 eta 0:36:54
epoch [9/50] batch [160/200] time 0.258 (0.267) data 0.000 (0.003) loss 0.1049 (0.4259) lr 1.9048e-02 eta 0:36:38
epoch [9/50] batch [180/200] time 0.257 (0.266) data 0.000 (0.003) loss 0.1719 (0.4377) lr 1.9048e-02 eta 0:36:26
epoch [9/50] batch [200/200] time 0.257 (0.265) data 0.000 (0.003) loss 0.5569 (0.4446) lr 1.8763e-02 eta 0:36:16
epoch [10/50] batch [20/200] time 0.258 (0.285) data 0.000 (0.023) loss 0.8980 (0.5707) lr 1.8763e-02 eta 0:38:50
epoch [10/50] batch [40/200] time 0.257 (0.272) data 0.000 (0.011) loss 1.0578 (0.5531) lr 1.8763e-02 eta 0:36:57
epoch [10/50] batch [60/200] time 0.313 (0.271) data 0.000 (0.008) loss 1.1374 (0.5231) lr 1.8763e-02 eta 0:36:44
epoch [10/50] batch [80/200] time 0.296 (0.280) data 0.000 (0.006) loss 0.1308 (0.5711) lr 1.8763e-02 eta 0:37:51
epoch [10/50] batch [100/200] time 0.305 (0.288) data 0.000 (0.005) loss 0.7012 (0.5231) lr 1.8763e-02 eta 0:38:52
epoch [10/50] batch [120/200] time 0.258 (0.290) data 0.000 (0.004) loss 0.0932 (0.5221) lr 1.8763e-02 eta 0:39:01
epoch [10/50] batch [140/200] time 0.258 (0.286) data 0.000 (0.003) loss 0.3247 (0.5023) lr 1.8763e-02 eta 0:38:27
epoch [10/50] batch [160/200] time 0.257 (0.285) data 0.000 (0.003) loss 0.4169 (0.5039) lr 1.8763e-02 eta 0:38:11
epoch [10/50] batch [180/200] time 0.257 (0.282) data 0.000 (0.003) loss 0.0069 (0.5126) lr 1.8763e-02 eta 0:37:43
epoch [10/50] batch [200/200] time 0.256 (0.280) data 0.000 (0.002) loss 0.2659 (0.4952) lr 1.8443e-02 eta 0:37:17
epoch [11/50] batch [20/200] time 0.258 (0.289) data 0.000 (0.024) loss 0.4524 (0.4992) lr 1.8443e-02 eta 0:38:28
epoch [11/50] batch [40/200] time 0.272 (0.282) data 0.000 (0.012) loss 0.1458 (0.4642) lr 1.8443e-02 eta 0:37:25
epoch [11/50] batch [60/200] time 0.261 (0.279) data 0.000 (0.008) loss 0.0756 (0.4931) lr 1.8443e-02 eta 0:36:53
epoch [11/50] batch [80/200] time 0.259 (0.275) data 0.000 (0.006) loss 0.0450 (0.4992) lr 1.8443e-02 eta 0:36:18
epoch [11/50] batch [100/200] time 0.260 (0.272) data 0.000 (0.005) loss 0.0506 (0.4893) lr 1.8443e-02 eta 0:35:48
epoch [11/50] batch [120/200] time 0.258 (0.271) data 0.000 (0.004) loss 0.0049 (0.4863) lr 1.8443e-02 eta 0:35:31
epoch [11/50] batch [140/200] time 0.257 (0.269) data 0.000 (0.004) loss 0.1121 (0.4596) lr 1.8443e-02 eta 0:35:15
epoch [11/50] batch [160/200] time 0.257 (0.268) data 0.000 (0.003) loss 0.0087 (0.4511) lr 1.8443e-02 eta 0:35:01
epoch [11/50] batch [180/200] time 0.259 (0.267) data 0.000 (0.003) loss 0.2868 (0.4590) lr 1.8443e-02 eta 0:34:47
epoch [11/50] batch [200/200] time 0.256 (0.267) data 0.000 (0.003) loss 0.1307 (0.4787) lr 1.8090e-02 eta 0:34:41
epoch [12/50] batch [20/200] time 0.266 (0.285) data 0.000 (0.023) loss 0.0111 (0.3922) lr 1.8090e-02 eta 0:36:53
epoch [12/50] batch [40/200] time 0.258 (0.272) data 0.000 (0.012) loss 0.0065 (0.3077) lr 1.8090e-02 eta 0:35:13
epoch [12/50] batch [60/200] time 0.258 (0.268) data 0.000 (0.008) loss 0.7046 (0.3310) lr 1.8090e-02 eta 0:34:36
epoch [12/50] batch [80/200] time 0.259 (0.267) data 0.000 (0.006) loss 0.5723 (0.3409) lr 1.8090e-02 eta 0:34:23
epoch [12/50] batch [100/200] time 0.257 (0.266) data 0.000 (0.005) loss 0.2303 (0.4013) lr 1.8090e-02 eta 0:34:05
epoch [12/50] batch [120/200] time 0.257 (0.264) data 0.000 (0.004) loss 0.4948 (0.4020) lr 1.8090e-02 eta 0:33:51
epoch [12/50] batch [140/200] time 0.258 (0.265) data 0.000 (0.003) loss 0.1866 (0.4098) lr 1.8090e-02 eta 0:33:46
epoch [12/50] batch [160/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.2422 (0.4281) lr 1.8090e-02 eta 0:33:35
epoch [12/50] batch [180/200] time 0.261 (0.264) data 0.000 (0.003) loss 0.0006 (0.4297) lr 1.8090e-02 eta 0:33:29
epoch [12/50] batch [200/200] time 0.255 (0.263) data 0.000 (0.002) loss 0.0661 (0.4155) lr 1.7705e-02 eta 0:33:18
epoch [13/50] batch [20/200] time 0.257 (0.292) data 0.000 (0.024) loss 0.3221 (0.4846) lr 1.7705e-02 eta 0:36:50
epoch [13/50] batch [40/200] time 0.257 (0.276) data 0.000 (0.012) loss 0.9953 (0.4792) lr 1.7705e-02 eta 0:34:45
epoch [13/50] batch [60/200] time 0.259 (0.271) data 0.000 (0.008) loss 1.2645 (0.4610) lr 1.7705e-02 eta 0:33:59
epoch [13/50] batch [80/200] time 0.258 (0.267) data 0.000 (0.006) loss 1.3663 (0.4368) lr 1.7705e-02 eta 0:33:31
epoch [13/50] batch [100/200] time 0.258 (0.266) data 0.000 (0.005) loss 1.0097 (0.4327) lr 1.7705e-02 eta 0:33:17
epoch [13/50] batch [120/200] time 0.260 (0.265) data 0.000 (0.004) loss 0.1022 (0.4151) lr 1.7705e-02 eta 0:33:01
epoch [13/50] batch [140/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.4881 (0.3889) lr 1.7705e-02 eta 0:32:50
epoch [13/50] batch [160/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.3432 (0.4007) lr 1.7705e-02 eta 0:32:40
epoch [13/50] batch [180/200] time 0.260 (0.264) data 0.000 (0.003) loss 0.9024 (0.4142) lr 1.7705e-02 eta 0:32:35
epoch [13/50] batch [200/200] time 0.256 (0.263) data 0.000 (0.003) loss 0.2533 (0.4127) lr 1.7290e-02 eta 0:32:25
epoch [14/50] batch [20/200] time 0.259 (0.285) data 0.000 (0.023) loss 0.0902 (0.4328) lr 1.7290e-02 eta 0:35:00
epoch [14/50] batch [40/200] time 0.258 (0.272) data 0.000 (0.012) loss 0.3335 (0.4111) lr 1.7290e-02 eta 0:33:21
epoch [14/50] batch [60/200] time 0.258 (0.269) data 0.001 (0.008) loss 0.2949 (0.3774) lr 1.7290e-02 eta 0:32:55
epoch [14/50] batch [80/200] time 0.258 (0.267) data 0.000 (0.006) loss 0.0496 (0.3684) lr 1.7290e-02 eta 0:32:31
epoch [14/50] batch [100/200] time 0.261 (0.265) data 0.000 (0.005) loss 1.3660 (0.4239) lr 1.7290e-02 eta 0:32:15
epoch [14/50] batch [120/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.0160 (0.4040) lr 1.7290e-02 eta 0:32:03
epoch [14/50] batch [140/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.1423 (0.3983) lr 1.7290e-02 eta 0:31:57
epoch [14/50] batch [160/200] time 0.257 (0.263) data 0.000 (0.003) loss 0.2400 (0.3963) lr 1.7290e-02 eta 0:31:47
epoch [14/50] batch [180/200] time 0.258 (0.263) data 0.000 (0.003) loss 0.0945 (0.4177) lr 1.7290e-02 eta 0:31:37
epoch [14/50] batch [200/200] time 0.256 (0.263) data 0.000 (0.002) loss 0.1392 (0.4021) lr 1.6845e-02 eta 0:31:31
epoch [15/50] batch [20/200] time 0.257 (0.285) data 0.000 (0.023) loss 0.1024 (0.4763) lr 1.6845e-02 eta 0:34:03
epoch [15/50] batch [40/200] time 0.258 (0.272) data 0.000 (0.012) loss 0.0042 (0.3448) lr 1.6845e-02 eta 0:32:27
epoch [15/50] batch [60/200] time 0.258 (0.268) data 0.000 (0.008) loss 0.0977 (0.3459) lr 1.6845e-02 eta 0:31:50
epoch [15/50] batch [80/200] time 0.257 (0.267) data 0.000 (0.006) loss 0.0193 (0.3798) lr 1.6845e-02 eta 0:31:37
epoch [15/50] batch [100/200] time 0.258 (0.265) data 0.000 (0.005) loss 0.0176 (0.3646) lr 1.6845e-02 eta 0:31:20
epoch [15/50] batch [120/200] time 0.259 (0.264) data 0.000 (0.004) loss 0.1355 (0.3806) lr 1.6845e-02 eta 0:31:08
epoch [15/50] batch [140/200] time 0.261 (0.263) data 0.000 (0.003) loss 1.3431 (0.3819) lr 1.6845e-02 eta 0:30:57
epoch [15/50] batch [160/200] time 0.257 (0.263) data 0.000 (0.003) loss 0.9116 (0.3860) lr 1.6845e-02 eta 0:30:52
epoch [15/50] batch [180/200] time 0.272 (0.263) data 0.000 (0.003) loss 0.0155 (0.3742) lr 1.6845e-02 eta 0:30:43
epoch [15/50] batch [200/200] time 0.256 (0.262) data 0.000 (0.002) loss 0.0865 (0.3940) lr 1.6374e-02 eta 0:30:34
epoch [16/50] batch [20/200] time 0.260 (0.285) data 0.000 (0.023) loss 0.0330 (0.3259) lr 1.6374e-02 eta 0:33:10
epoch [16/50] batch [40/200] time 0.264 (0.275) data 0.000 (0.011) loss 0.2163 (0.2647) lr 1.6374e-02 eta 0:31:54
epoch [16/50] batch [60/200] time 0.259 (0.271) data 0.000 (0.008) loss 0.3080 (0.4033) lr 1.6374e-02 eta 0:31:19
epoch [16/50] batch [80/200] time 0.260 (0.268) data 0.000 (0.006) loss 0.1857 (0.3867) lr 1.6374e-02 eta 0:30:54
epoch [16/50] batch [100/200] time 0.259 (0.266) data 0.000 (0.005) loss 0.1547 (0.3918) lr 1.6374e-02 eta 0:30:38
epoch [16/50] batch [120/200] time 0.260 (0.266) data 0.000 (0.004) loss 0.4708 (0.4047) lr 1.6374e-02 eta 0:30:30
epoch [16/50] batch [140/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.3517 (0.3857) lr 1.6374e-02 eta 0:30:19
epoch [16/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.1639 (0.4004) lr 1.6374e-02 eta 0:30:09
epoch [16/50] batch [180/200] time 0.259 (0.264) data 0.000 (0.003) loss 0.0074 (0.4048) lr 1.6374e-02 eta 0:30:00
epoch [16/50] batch [200/200] time 0.257 (0.264) data 0.000 (0.002) loss 0.0308 (0.3968) lr 1.5878e-02 eta 0:29:53
epoch [17/50] batch [20/200] time 0.258 (0.283) data 0.000 (0.024) loss 0.1771 (0.4105) lr 1.5878e-02 eta 0:31:58
epoch [17/50] batch [40/200] time 0.261 (0.272) data 0.000 (0.012) loss 0.3983 (0.3776) lr 1.5878e-02 eta 0:30:39
epoch [17/50] batch [60/200] time 0.258 (0.267) data 0.000 (0.008) loss 0.0462 (0.3549) lr 1.5878e-02 eta 0:30:02
epoch [17/50] batch [80/200] time 0.263 (0.267) data 0.000 (0.006) loss 0.8549 (0.3374) lr 1.5878e-02 eta 0:29:50
epoch [17/50] batch [100/200] time 0.257 (0.266) data 0.000 (0.005) loss 0.0006 (0.3478) lr 1.5878e-02 eta 0:29:39
epoch [17/50] batch [120/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.7794 (0.3770) lr 1.5878e-02 eta 0:29:25
epoch [17/50] batch [140/200] time 0.275 (0.264) data 0.000 (0.004) loss 1.3893 (0.3805) lr 1.5878e-02 eta 0:29:17
epoch [17/50] batch [160/200] time 0.263 (0.264) data 0.000 (0.003) loss 0.0454 (0.3812) lr 1.5878e-02 eta 0:29:12
epoch [17/50] batch [180/200] time 0.260 (0.263) data 0.000 (0.003) loss 0.4617 (0.3894) lr 1.5878e-02 eta 0:29:02
epoch [17/50] batch [200/200] time 0.256 (0.263) data 0.000 (0.003) loss 0.3196 (0.3948) lr 1.5358e-02 eta 0:28:54
epoch [18/50] batch [20/200] time 0.398 (0.291) data 0.000 (0.023) loss 0.0085 (0.5737) lr 1.5358e-02 eta 0:31:53
epoch [18/50] batch [40/200] time 0.272 (0.280) data 0.000 (0.012) loss 0.1097 (0.4729) lr 1.5358e-02 eta 0:30:39
epoch [18/50] batch [60/200] time 0.262 (0.275) data 0.001 (0.008) loss 0.0861 (0.3999) lr 1.5358e-02 eta 0:29:59
epoch [18/50] batch [80/200] time 0.260 (0.272) data 0.000 (0.006) loss 0.4520 (0.4000) lr 1.5358e-02 eta 0:29:34
epoch [18/50] batch [100/200] time 0.264 (0.270) data 0.000 (0.005) loss 0.6206 (0.3884) lr 1.5358e-02 eta 0:29:15
epoch [18/50] batch [120/200] time 0.258 (0.271) data 0.000 (0.004) loss 0.1418 (0.3886) lr 1.5358e-02 eta 0:29:13
epoch [18/50] batch [140/200] time 0.260 (0.269) data 0.000 (0.003) loss 0.5612 (0.4067) lr 1.5358e-02 eta 0:28:59
epoch [18/50] batch [160/200] time 0.311 (0.269) data 0.000 (0.003) loss 2.4093 (0.4139) lr 1.5358e-02 eta 0:28:51
epoch [18/50] batch [180/200] time 0.374 (0.269) data 0.000 (0.003) loss 0.0060 (0.4260) lr 1.5358e-02 eta 0:28:47
epoch [18/50] batch [200/200] time 0.261 (0.269) data 0.000 (0.002) loss 0.0281 (0.4068) lr 1.4818e-02 eta 0:28:43
epoch [19/50] batch [20/200] time 0.264 (0.294) data 0.000 (0.030) loss 0.0282 (0.2494) lr 1.4818e-02 eta 0:31:18
epoch [19/50] batch [40/200] time 0.263 (0.279) data 0.000 (0.015) loss 0.3265 (0.3425) lr 1.4818e-02 eta 0:29:33
epoch [19/50] batch [60/200] time 0.265 (0.276) data 0.001 (0.010) loss 1.7940 (0.3849) lr 1.4818e-02 eta 0:29:07
epoch [19/50] batch [80/200] time 0.260 (0.272) data 0.000 (0.008) loss 0.8654 (0.3650) lr 1.4818e-02 eta 0:28:39
epoch [19/50] batch [100/200] time 0.260 (0.270) data 0.000 (0.006) loss 0.3257 (0.3566) lr 1.4818e-02 eta 0:28:22
epoch [19/50] batch [120/200] time 0.264 (0.269) data 0.000 (0.005) loss 0.1260 (0.3480) lr 1.4818e-02 eta 0:28:08
epoch [19/50] batch [140/200] time 0.262 (0.268) data 0.000 (0.004) loss 0.1670 (0.3407) lr 1.4818e-02 eta 0:27:59
epoch [19/50] batch [160/200] time 0.261 (0.268) data 0.000 (0.004) loss 0.4061 (0.3693) lr 1.4818e-02 eta 0:27:49
epoch [19/50] batch [180/200] time 0.263 (0.268) data 0.000 (0.003) loss 0.0160 (0.3703) lr 1.4818e-02 eta 0:27:46
epoch [19/50] batch [200/200] time 0.257 (0.268) data 0.000 (0.003) loss 0.1837 (0.3600) lr 1.4258e-02 eta 0:27:39
epoch [20/50] batch [20/200] time 0.261 (0.303) data 0.000 (0.030) loss 0.0115 (0.3285) lr 1.4258e-02 eta 0:31:15
epoch [20/50] batch [40/200] time 0.263 (0.287) data 0.000 (0.015) loss 1.0098 (0.3423) lr 1.4258e-02 eta 0:29:27
epoch [20/50] batch [60/200] time 0.260 (0.278) data 0.001 (0.010) loss 0.0819 (0.3493) lr 1.4258e-02 eta 0:28:29
epoch [20/50] batch [80/200] time 0.261 (0.275) data 0.000 (0.008) loss 0.0024 (0.3517) lr 1.4258e-02 eta 0:28:00
epoch [20/50] batch [100/200] time 0.260 (0.274) data 0.000 (0.006) loss 0.1494 (0.3442) lr 1.4258e-02 eta 0:27:50
epoch [20/50] batch [120/200] time 0.261 (0.272) data 0.000 (0.005) loss 0.8520 (0.3458) lr 1.4258e-02 eta 0:27:33
epoch [20/50] batch [140/200] time 0.263 (0.272) data 0.000 (0.004) loss 0.0678 (0.3614) lr 1.4258e-02 eta 0:27:25
epoch [20/50] batch [160/200] time 0.260 (0.271) data 0.000 (0.004) loss 0.0531 (0.3509) lr 1.4258e-02 eta 0:27:14
epoch [20/50] batch [180/200] time 0.260 (0.271) data 0.000 (0.003) loss 0.0992 (0.3706) lr 1.4258e-02 eta 0:27:10
epoch [20/50] batch [200/200] time 0.259 (0.270) data 0.000 (0.003) loss 0.1533 (0.3757) lr 1.3681e-02 eta 0:26:59
epoch [21/50] batch [20/200] time 0.282 (0.293) data 0.000 (0.029) loss 0.0021 (0.2808) lr 1.3681e-02 eta 0:29:11
epoch [21/50] batch [40/200] time 0.262 (0.278) data 0.000 (0.015) loss 0.1290 (0.3021) lr 1.3681e-02 eta 0:27:38
epoch [21/50] batch [60/200] time 0.293 (0.275) data 0.000 (0.010) loss 0.2204 (0.3120) lr 1.3681e-02 eta 0:27:15
epoch [21/50] batch [80/200] time 0.260 (0.272) data 0.000 (0.008) loss 0.0920 (0.2894) lr 1.3681e-02 eta 0:26:52
epoch [21/50] batch [100/200] time 0.263 (0.271) data 0.000 (0.006) loss 0.1629 (0.3519) lr 1.3681e-02 eta 0:26:36
epoch [21/50] batch [120/200] time 0.262 (0.269) data 0.000 (0.005) loss 0.5405 (0.3795) lr 1.3681e-02 eta 0:26:22
epoch [21/50] batch [140/200] time 0.260 (0.271) data 0.000 (0.004) loss 0.0209 (0.3708) lr 1.3681e-02 eta 0:26:25
epoch [21/50] batch [160/200] time 0.261 (0.269) data 0.000 (0.004) loss 0.5559 (0.3695) lr 1.3681e-02 eta 0:26:13
epoch [21/50] batch [180/200] time 0.261 (0.269) data 0.000 (0.003) loss 0.2248 (0.3716) lr 1.3681e-02 eta 0:26:03
epoch [21/50] batch [200/200] time 0.258 (0.268) data 0.000 (0.003) loss 0.1619 (0.3675) lr 1.3090e-02 eta 0:25:53
epoch [22/50] batch [20/200] time 0.260 (0.312) data 0.000 (0.030) loss 0.0021 (0.3664) lr 1.3090e-02 eta 0:30:00
epoch [22/50] batch [40/200] time 0.259 (0.287) data 0.000 (0.015) loss 0.0047 (0.3248) lr 1.3090e-02 eta 0:27:34
epoch [22/50] batch [60/200] time 0.261 (0.279) data 0.001 (0.010) loss 0.1145 (0.3373) lr 1.3090e-02 eta 0:26:39
epoch [22/50] batch [80/200] time 0.260 (0.274) data 0.000 (0.008) loss 0.6358 (0.3773) lr 1.3090e-02 eta 0:26:07
epoch [22/50] batch [100/200] time 0.261 (0.273) data 0.000 (0.006) loss 0.1711 (0.4031) lr 1.3090e-02 eta 0:25:54
epoch [22/50] batch [120/200] time 0.263 (0.271) data 0.000 (0.005) loss 0.5658 (0.4108) lr 1.3090e-02 eta 0:25:40
epoch [22/50] batch [140/200] time 0.267 (0.270) data 0.000 (0.004) loss 0.7181 (0.4156) lr 1.3090e-02 eta 0:25:27
epoch [22/50] batch [160/200] time 0.261 (0.269) data 0.000 (0.004) loss 0.4355 (0.4204) lr 1.3090e-02 eta 0:25:16
epoch [22/50] batch [180/200] time 0.261 (0.269) data 0.000 (0.003) loss 0.2990 (0.4328) lr 1.3090e-02 eta 0:25:09
epoch [22/50] batch [200/200] time 0.264 (0.268) data 0.000 (0.003) loss 0.8436 (0.4335) lr 1.2487e-02 eta 0:24:59
epoch [23/50] batch [20/200] time 0.260 (0.291) data 0.000 (0.030) loss 0.0575 (0.3379) lr 1.2487e-02 eta 0:27:05
epoch [23/50] batch [40/200] time 0.381 (0.286) data 0.000 (0.015) loss 0.3041 (0.3944) lr 1.2487e-02 eta 0:26:29
epoch [23/50] batch [60/200] time 0.260 (0.278) data 0.001 (0.010) loss 0.0999 (0.3486) lr 1.2487e-02 eta 0:25:40
epoch [23/50] batch [80/200] time 0.261 (0.274) data 0.000 (0.008) loss 0.9598 (0.3298) lr 1.2487e-02 eta 0:25:12
epoch [23/50] batch [100/200] time 0.262 (0.272) data 0.000 (0.006) loss 0.0393 (0.3257) lr 1.2487e-02 eta 0:24:53
epoch [23/50] batch [120/200] time 0.260 (0.271) data 0.000 (0.005) loss 0.5900 (0.3380) lr 1.2487e-02 eta 0:24:46
epoch [23/50] batch [140/200] time 0.261 (0.270) data 0.000 (0.004) loss 0.2049 (0.3482) lr 1.2487e-02 eta 0:24:34
epoch [23/50] batch [160/200] time 0.263 (0.269) data 0.000 (0.004) loss 0.1827 (0.3392) lr 1.2487e-02 eta 0:24:22
epoch [23/50] batch [180/200] time 0.260 (0.268) data 0.000 (0.003) loss 1.3110 (0.3486) lr 1.2487e-02 eta 0:24:12
epoch [23/50] batch [200/200] time 0.258 (0.268) data 0.000 (0.003) loss 1.0124 (0.3696) lr 1.1874e-02 eta 0:24:05
epoch [24/50] batch [20/200] time 0.261 (0.293) data 0.000 (0.030) loss 0.1724 (0.2293) lr 1.1874e-02 eta 0:26:16
epoch [24/50] batch [40/200] time 0.261 (0.277) data 0.000 (0.015) loss 0.3185 (0.2830) lr 1.1874e-02 eta 0:24:44
epoch [24/50] batch [60/200] time 0.263 (0.272) data 0.000 (0.010) loss 0.1640 (0.3217) lr 1.1874e-02 eta 0:24:10
epoch [24/50] batch [80/200] time 0.257 (0.270) data 0.000 (0.008) loss 0.6623 (0.3294) lr 1.1874e-02 eta 0:23:58
epoch [24/50] batch [100/200] time 0.260 (0.269) data 0.000 (0.006) loss 0.0012 (0.3707) lr 1.1874e-02 eta 0:23:44
epoch [24/50] batch [120/200] time 0.262 (0.268) data 0.000 (0.005) loss 1.1738 (0.3460) lr 1.1874e-02 eta 0:23:32
epoch [24/50] batch [140/200] time 0.262 (0.267) data 0.000 (0.004) loss 0.0024 (0.3524) lr 1.1874e-02 eta 0:23:26
epoch [24/50] batch [160/200] time 0.304 (0.268) data 0.000 (0.004) loss 0.0177 (0.3563) lr 1.1874e-02 eta 0:23:22
epoch [24/50] batch [180/200] time 0.260 (0.267) data 0.000 (0.003) loss 0.5221 (0.3527) lr 1.1874e-02 eta 0:23:14
epoch [24/50] batch [200/200] time 0.273 (0.267) data 0.000 (0.003) loss 0.0046 (0.3550) lr 1.1253e-02 eta 0:23:06
epoch [25/50] batch [20/200] time 0.258 (0.285) data 0.000 (0.025) loss 0.0901 (0.4039) lr 1.1253e-02 eta 0:24:37
epoch [25/50] batch [40/200] time 0.262 (0.276) data 0.000 (0.012) loss 0.0059 (0.4823) lr 1.1253e-02 eta 0:23:43
epoch [25/50] batch [60/200] time 0.258 (0.271) data 0.000 (0.008) loss 0.0802 (0.3779) lr 1.1253e-02 eta 0:23:12
epoch [25/50] batch [80/200] time 0.259 (0.268) data 0.000 (0.006) loss 1.2931 (0.4325) lr 1.1253e-02 eta 0:22:51
epoch [25/50] batch [100/200] time 0.259 (0.267) data 0.000 (0.005) loss 0.1815 (0.4532) lr 1.1253e-02 eta 0:22:39
epoch [25/50] batch [120/200] time 0.259 (0.267) data 0.000 (0.004) loss 0.4784 (0.4486) lr 1.1253e-02 eta 0:22:35
epoch [25/50] batch [140/200] time 0.258 (0.266) data 0.000 (0.004) loss 0.0027 (0.4225) lr 1.1253e-02 eta 0:22:24
epoch [25/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0520 (0.4113) lr 1.1253e-02 eta 0:22:15
epoch [25/50] batch [180/200] time 0.332 (0.265) data 0.000 (0.003) loss 0.0901 (0.3954) lr 1.1253e-02 eta 0:22:08
epoch [25/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.5630 (0.4028) lr 1.0628e-02 eta 0:22:00
epoch [26/50] batch [20/200] time 0.260 (0.288) data 0.000 (0.023) loss 0.2863 (0.3629) lr 1.0628e-02 eta 0:23:52
epoch [26/50] batch [40/200] time 0.259 (0.275) data 0.000 (0.011) loss 1.3440 (0.3744) lr 1.0628e-02 eta 0:22:41
epoch [26/50] batch [60/200] time 0.273 (0.276) data 0.000 (0.008) loss 0.0101 (0.3346) lr 1.0628e-02 eta 0:22:43
epoch [26/50] batch [80/200] time 0.274 (0.275) data 0.000 (0.006) loss 2.0241 (0.3837) lr 1.0628e-02 eta 0:22:34
epoch [26/50] batch [100/200] time 0.273 (0.275) data 0.000 (0.005) loss 0.2940 (0.3556) lr 1.0628e-02 eta 0:22:26
epoch [26/50] batch [120/200] time 0.273 (0.275) data 0.000 (0.004) loss 0.0030 (0.3548) lr 1.0628e-02 eta 0:22:22
epoch [26/50] batch [140/200] time 0.273 (0.274) data 0.000 (0.003) loss 0.1198 (0.3471) lr 1.0628e-02 eta 0:22:13
epoch [26/50] batch [160/200] time 0.274 (0.274) data 0.000 (0.003) loss 0.1958 (0.3442) lr 1.0628e-02 eta 0:22:07
epoch [26/50] batch [180/200] time 0.274 (0.274) data 0.000 (0.003) loss 0.0410 (0.3433) lr 1.0628e-02 eta 0:22:01
epoch [26/50] batch [200/200] time 0.270 (0.274) data 0.000 (0.002) loss 0.1430 (0.3564) lr 1.0000e-02 eta 0:21:54
epoch [27/50] batch [20/200] time 0.258 (0.290) data 0.000 (0.024) loss 0.5587 (0.4186) lr 1.0000e-02 eta 0:23:05
epoch [27/50] batch [40/200] time 0.262 (0.275) data 0.000 (0.012) loss 0.0109 (0.3273) lr 1.0000e-02 eta 0:21:47
epoch [27/50] batch [60/200] time 0.259 (0.270) data 0.000 (0.008) loss 1.1927 (0.3465) lr 1.0000e-02 eta 0:21:20
epoch [27/50] batch [80/200] time 0.259 (0.267) data 0.000 (0.006) loss 0.7111 (0.3621) lr 1.0000e-02 eta 0:21:01
epoch [27/50] batch [100/200] time 0.259 (0.267) data 0.000 (0.005) loss 0.3958 (0.4127) lr 1.0000e-02 eta 0:20:53
epoch [27/50] batch [120/200] time 0.261 (0.265) data 0.000 (0.004) loss 0.0299 (0.4244) lr 1.0000e-02 eta 0:20:41
epoch [27/50] batch [140/200] time 0.258 (0.265) data 0.000 (0.004) loss 0.3590 (0.4030) lr 1.0000e-02 eta 0:20:34
epoch [27/50] batch [160/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.3553 (0.3888) lr 1.0000e-02 eta 0:20:26
epoch [27/50] batch [180/200] time 0.259 (0.264) data 0.000 (0.003) loss 0.5011 (0.3817) lr 1.0000e-02 eta 0:20:20
epoch [27/50] batch [200/200] time 0.260 (0.264) data 0.000 (0.003) loss 0.0768 (0.3908) lr 9.3721e-03 eta 0:20:12
epoch [28/50] batch [20/200] time 0.260 (0.284) data 0.000 (0.023) loss 0.0546 (0.2649) lr 9.3721e-03 eta 0:21:42
epoch [28/50] batch [40/200] time 0.259 (0.272) data 0.000 (0.012) loss 0.0393 (0.2683) lr 9.3721e-03 eta 0:20:41
epoch [28/50] batch [60/200] time 0.259 (0.271) data 0.000 (0.008) loss 0.0521 (0.2985) lr 9.3721e-03 eta 0:20:28
epoch [28/50] batch [80/200] time 0.301 (0.268) data 0.000 (0.006) loss 0.0382 (0.3089) lr 9.3721e-03 eta 0:20:12
epoch [28/50] batch [100/200] time 0.258 (0.266) data 0.000 (0.005) loss 2.2119 (0.3295) lr 9.3721e-03 eta 0:19:58
epoch [28/50] batch [120/200] time 0.272 (0.266) data 0.000 (0.004) loss 0.0965 (0.3062) lr 9.3721e-03 eta 0:19:52
epoch [28/50] batch [140/200] time 0.258 (0.266) data 0.000 (0.003) loss 0.0010 (0.2926) lr 9.3721e-03 eta 0:19:48
epoch [28/50] batch [160/200] time 0.258 (0.266) data 0.000 (0.003) loss 0.0098 (0.3026) lr 9.3721e-03 eta 0:19:39
epoch [28/50] batch [180/200] time 0.258 (0.265) data 0.000 (0.003) loss 0.1696 (0.3162) lr 9.3721e-03 eta 0:19:30
epoch [28/50] batch [200/200] time 0.257 (0.265) data 0.000 (0.002) loss 0.6303 (0.3204) lr 8.7467e-03 eta 0:19:24
epoch [29/50] batch [20/200] time 0.259 (0.289) data 0.000 (0.024) loss 0.2469 (0.2966) lr 8.7467e-03 eta 0:21:06
epoch [29/50] batch [40/200] time 0.258 (0.274) data 0.000 (0.012) loss 0.0081 (0.3308) lr 8.7467e-03 eta 0:19:55
epoch [29/50] batch [60/200] time 0.258 (0.270) data 0.000 (0.008) loss 0.7616 (0.3820) lr 8.7467e-03 eta 0:19:29
epoch [29/50] batch [80/200] time 0.257 (0.267) data 0.000 (0.006) loss 0.9893 (0.3821) lr 8.7467e-03 eta 0:19:12
epoch [29/50] batch [100/200] time 0.258 (0.266) data 0.000 (0.005) loss 0.9623 (0.3687) lr 8.7467e-03 eta 0:19:03
epoch [29/50] batch [120/200] time 0.258 (0.265) data 0.000 (0.004) loss 0.1290 (0.3532) lr 8.7467e-03 eta 0:18:52
epoch [29/50] batch [140/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.1845 (0.3567) lr 8.7467e-03 eta 0:18:43
epoch [29/50] batch [160/200] time 0.258 (0.263) data 0.000 (0.003) loss 0.0619 (0.3515) lr 8.7467e-03 eta 0:18:36
epoch [29/50] batch [180/200] time 0.260 (0.264) data 0.000 (0.003) loss 0.0318 (0.3587) lr 8.7467e-03 eta 0:18:32
epoch [29/50] batch [200/200] time 0.258 (0.263) data 0.000 (0.003) loss 0.1186 (0.3515) lr 8.1262e-03 eta 0:18:24
epoch [30/50] batch [20/200] time 0.257 (0.286) data 0.000 (0.023) loss 0.0038 (0.3075) lr 8.1262e-03 eta 0:19:53
epoch [30/50] batch [40/200] time 0.261 (0.272) data 0.000 (0.012) loss 0.0599 (0.2965) lr 8.1262e-03 eta 0:18:50
epoch [30/50] batch [60/200] time 0.258 (0.269) data 0.000 (0.008) loss 0.1201 (0.3610) lr 8.1262e-03 eta 0:18:34
epoch [30/50] batch [80/200] time 0.257 (0.267) data 0.000 (0.006) loss 1.7283 (0.3618) lr 8.1262e-03 eta 0:18:21
epoch [30/50] batch [100/200] time 0.259 (0.266) data 0.000 (0.005) loss 0.0129 (0.3722) lr 8.1262e-03 eta 0:18:10
epoch [30/50] batch [120/200] time 0.257 (0.265) data 0.000 (0.004) loss 0.0203 (0.3634) lr 8.1262e-03 eta 0:17:59
epoch [30/50] batch [140/200] time 0.258 (0.264) data 0.000 (0.003) loss 1.4234 (0.3628) lr 8.1262e-03 eta 0:17:52
epoch [30/50] batch [160/200] time 0.257 (0.265) data 0.000 (0.003) loss 0.1495 (0.3502) lr 8.1262e-03 eta 0:17:49
epoch [30/50] batch [180/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.1263 (0.3610) lr 8.1262e-03 eta 0:17:41
epoch [30/50] batch [200/200] time 0.255 (0.263) data 0.000 (0.002) loss 0.6241 (0.3548) lr 7.5131e-03 eta 0:17:33
epoch [31/50] batch [20/200] time 0.257 (0.290) data 0.000 (0.023) loss 0.0021 (0.2323) lr 7.5131e-03 eta 0:19:14
epoch [31/50] batch [40/200] time 0.260 (0.274) data 0.000 (0.011) loss 1.0021 (0.2550) lr 7.5131e-03 eta 0:18:06
epoch [31/50] batch [60/200] time 0.258 (0.269) data 0.000 (0.008) loss 0.0298 (0.2929) lr 7.5131e-03 eta 0:17:41
epoch [31/50] batch [80/200] time 0.259 (0.267) data 0.000 (0.006) loss 0.1615 (0.3348) lr 7.5131e-03 eta 0:17:25
epoch [31/50] batch [100/200] time 0.264 (0.267) data 0.000 (0.005) loss 0.0022 (0.3230) lr 7.5131e-03 eta 0:17:21
epoch [31/50] batch [120/200] time 0.280 (0.268) data 0.000 (0.004) loss 0.8581 (0.3273) lr 7.5131e-03 eta 0:17:19
epoch [31/50] batch [140/200] time 0.273 (0.269) data 0.000 (0.003) loss 0.7096 (0.3333) lr 7.5131e-03 eta 0:17:17
epoch [31/50] batch [160/200] time 0.273 (0.270) data 0.000 (0.003) loss 1.2982 (0.3379) lr 7.5131e-03 eta 0:17:16
epoch [31/50] batch [180/200] time 0.274 (0.270) data 0.000 (0.003) loss 0.0181 (0.3325) lr 7.5131e-03 eta 0:17:10
epoch [31/50] batch [200/200] time 0.270 (0.270) data 0.000 (0.002) loss 0.0332 (0.3269) lr 6.9098e-03 eta 0:17:06
epoch [32/50] batch [20/200] time 0.257 (0.285) data 0.000 (0.023) loss 0.4676 (0.2849) lr 6.9098e-03 eta 0:17:55
epoch [32/50] batch [40/200] time 0.257 (0.274) data 0.000 (0.012) loss 0.5445 (0.3414) lr 6.9098e-03 eta 0:17:09
epoch [32/50] batch [60/200] time 0.258 (0.269) data 0.000 (0.008) loss 0.3247 (0.2971) lr 6.9098e-03 eta 0:16:46
epoch [32/50] batch [80/200] time 0.274 (0.267) data 0.000 (0.006) loss 0.3049 (0.3239) lr 6.9098e-03 eta 0:16:33
epoch [32/50] batch [100/200] time 0.261 (0.266) data 0.000 (0.005) loss 0.3956 (0.3123) lr 6.9098e-03 eta 0:16:24
epoch [32/50] batch [120/200] time 0.263 (0.268) data 0.000 (0.004) loss 0.8328 (0.3184) lr 6.9098e-03 eta 0:16:25
epoch [32/50] batch [140/200] time 0.261 (0.267) data 0.000 (0.003) loss 0.3924 (0.3296) lr 6.9098e-03 eta 0:16:16
epoch [32/50] batch [160/200] time 0.264 (0.266) data 0.000 (0.003) loss 0.3322 (0.3197) lr 6.9098e-03 eta 0:16:09
epoch [32/50] batch [180/200] time 0.261 (0.266) data 0.000 (0.003) loss 0.0213 (0.3256) lr 6.9098e-03 eta 0:16:02
epoch [32/50] batch [200/200] time 0.258 (0.266) data 0.000 (0.002) loss 0.0557 (0.3192) lr 6.3188e-03 eta 0:15:56
epoch [33/50] batch [20/200] time 0.261 (0.293) data 0.000 (0.029) loss 0.0102 (0.3509) lr 6.3188e-03 eta 0:17:27
epoch [33/50] batch [40/200] time 0.261 (0.278) data 0.000 (0.015) loss 0.0494 (0.2994) lr 6.3188e-03 eta 0:16:28
epoch [33/50] batch [60/200] time 0.294 (0.273) data 0.000 (0.010) loss 0.5790 (0.2989) lr 6.3188e-03 eta 0:16:06
epoch [33/50] batch [80/200] time 0.263 (0.272) data 0.000 (0.008) loss 0.0023 (0.2930) lr 6.3188e-03 eta 0:15:57
epoch [33/50] batch [100/200] time 0.262 (0.270) data 0.000 (0.006) loss 0.0149 (0.2835) lr 6.3188e-03 eta 0:15:45
epoch [33/50] batch [120/200] time 0.261 (0.269) data 0.000 (0.005) loss 0.2067 (0.2812) lr 6.3188e-03 eta 0:15:35
epoch [33/50] batch [140/200] time 0.260 (0.268) data 0.000 (0.004) loss 0.2198 (0.2745) lr 6.3188e-03 eta 0:15:27
epoch [33/50] batch [160/200] time 0.263 (0.268) data 0.000 (0.004) loss 0.3542 (0.2946) lr 6.3188e-03 eta 0:15:22
epoch [33/50] batch [180/200] time 0.262 (0.267) data 0.000 (0.003) loss 0.0311 (0.3082) lr 6.3188e-03 eta 0:15:14
epoch [33/50] batch [200/200] time 0.259 (0.268) data 0.000 (0.003) loss 0.8312 (0.2994) lr 5.7422e-03 eta 0:15:09
epoch [34/50] batch [20/200] time 0.261 (0.300) data 0.000 (0.029) loss 0.4870 (0.3075) lr 5.7422e-03 eta 0:16:52
epoch [34/50] batch [40/200] time 0.311 (0.290) data 0.000 (0.015) loss 0.0351 (0.3056) lr 5.7422e-03 eta 0:16:12
epoch [34/50] batch [60/200] time 0.262 (0.286) data 0.001 (0.010) loss 0.3856 (0.3061) lr 5.7422e-03 eta 0:15:55
epoch [34/50] batch [80/200] time 0.293 (0.280) data 0.000 (0.007) loss 0.3952 (0.3112) lr 5.7422e-03 eta 0:15:30
epoch [34/50] batch [100/200] time 0.292 (0.280) data 0.000 (0.006) loss 0.7006 (0.2965) lr 5.7422e-03 eta 0:15:22
epoch [34/50] batch [120/200] time 0.260 (0.279) data 0.000 (0.005) loss 0.4106 (0.2837) lr 5.7422e-03 eta 0:15:16
epoch [34/50] batch [140/200] time 0.261 (0.277) data 0.000 (0.004) loss 0.0407 (0.2701) lr 5.7422e-03 eta 0:15:02
epoch [34/50] batch [160/200] time 0.265 (0.275) data 0.000 (0.004) loss 1.2396 (0.2788) lr 5.7422e-03 eta 0:14:50
epoch [34/50] batch [180/200] time 0.260 (0.273) data 0.000 (0.003) loss 3.9083 (0.3019) lr 5.7422e-03 eta 0:14:39
epoch [34/50] batch [200/200] time 0.257 (0.272) data 0.000 (0.003) loss 1.8214 (0.3397) lr 5.1825e-03 eta 0:14:30
epoch [35/50] batch [20/200] time 0.260 (0.291) data 0.000 (0.029) loss 0.0886 (0.2551) lr 5.1825e-03 eta 0:15:26
epoch [35/50] batch [40/200] time 0.261 (0.277) data 0.000 (0.015) loss 0.3447 (0.4073) lr 5.1825e-03 eta 0:14:35
epoch [35/50] batch [60/200] time 0.280 (0.272) data 0.000 (0.010) loss 0.2711 (0.3455) lr 5.1825e-03 eta 0:14:15
epoch [35/50] batch [80/200] time 0.261 (0.272) data 0.000 (0.007) loss 0.3649 (0.3262) lr 5.1825e-03 eta 0:14:09
epoch [35/50] batch [100/200] time 0.260 (0.270) data 0.000 (0.006) loss 0.0819 (0.2995) lr 5.1825e-03 eta 0:13:57
epoch [35/50] batch [120/200] time 0.265 (0.269) data 0.000 (0.005) loss 0.1279 (0.3281) lr 5.1825e-03 eta 0:13:48
epoch [35/50] batch [140/200] time 0.259 (0.268) data 0.000 (0.004) loss 0.6486 (0.3439) lr 5.1825e-03 eta 0:13:40
epoch [35/50] batch [160/200] time 0.262 (0.268) data 0.000 (0.004) loss 0.0095 (0.3406) lr 5.1825e-03 eta 0:13:34
epoch [35/50] batch [180/200] time 0.263 (0.269) data 0.000 (0.003) loss 0.0023 (0.3345) lr 5.1825e-03 eta 0:13:31
epoch [35/50] batch [200/200] time 0.260 (0.268) data 0.000 (0.003) loss 0.6218 (0.3305) lr 4.6417e-03 eta 0:13:24
epoch [36/50] batch [20/200] time 0.260 (0.293) data 0.000 (0.030) loss 0.8433 (0.5122) lr 4.6417e-03 eta 0:14:31
epoch [36/50] batch [40/200] time 0.258 (0.281) data 0.000 (0.015) loss 0.7274 (0.4049) lr 4.6417e-03 eta 0:13:51
epoch [36/50] batch [60/200] time 0.259 (0.278) data 0.001 (0.010) loss 0.0819 (0.3189) lr 4.6417e-03 eta 0:13:36
epoch [36/50] batch [80/200] time 0.260 (0.274) data 0.000 (0.008) loss 0.2735 (0.3288) lr 4.6417e-03 eta 0:13:18
epoch [36/50] batch [100/200] time 0.261 (0.272) data 0.000 (0.006) loss 0.5097 (0.3026) lr 4.6417e-03 eta 0:13:08
epoch [36/50] batch [120/200] time 0.259 (0.270) data 0.000 (0.005) loss 0.7062 (0.3003) lr 4.6417e-03 eta 0:12:57
epoch [36/50] batch [140/200] time 0.259 (0.270) data 0.000 (0.004) loss 0.0007 (0.3144) lr 4.6417e-03 eta 0:12:51
epoch [36/50] batch [160/200] time 0.313 (0.270) data 0.000 (0.004) loss 0.1046 (0.3094) lr 4.6417e-03 eta 0:12:46
epoch [36/50] batch [180/200] time 0.260 (0.271) data 0.000 (0.003) loss 0.6382 (0.2974) lr 4.6417e-03 eta 0:12:43
epoch [36/50] batch [200/200] time 0.258 (0.271) data 0.000 (0.003) loss 1.2054 (0.3185) lr 4.1221e-03 eta 0:12:37
epoch [37/50] batch [20/200] time 0.260 (0.292) data 0.000 (0.030) loss 0.1000 (0.3139) lr 4.1221e-03 eta 0:13:31
epoch [37/50] batch [40/200] time 0.260 (0.285) data 0.000 (0.015) loss 1.4190 (0.3376) lr 4.1221e-03 eta 0:13:05
epoch [37/50] batch [60/200] time 0.261 (0.279) data 0.001 (0.010) loss 0.0145 (0.3240) lr 4.1221e-03 eta 0:12:44
epoch [37/50] batch [80/200] time 0.260 (0.275) data 0.000 (0.008) loss 0.4709 (0.3412) lr 4.1221e-03 eta 0:12:28
epoch [37/50] batch [100/200] time 0.260 (0.274) data 0.000 (0.006) loss 0.1559 (0.3227) lr 4.1221e-03 eta 0:12:19
epoch [37/50] batch [120/200] time 0.290 (0.273) data 0.000 (0.005) loss 0.1209 (0.3061) lr 4.1221e-03 eta 0:12:11
epoch [37/50] batch [140/200] time 0.262 (0.274) data 0.000 (0.004) loss 0.0030 (0.2871) lr 4.1221e-03 eta 0:12:08
epoch [37/50] batch [160/200] time 0.260 (0.272) data 0.000 (0.004) loss 0.2134 (0.3005) lr 4.1221e-03 eta 0:11:58
epoch [37/50] batch [180/200] time 0.260 (0.271) data 0.000 (0.003) loss 0.0321 (0.2869) lr 4.1221e-03 eta 0:11:50
epoch [37/50] batch [200/200] time 0.258 (0.270) data 0.000 (0.003) loss 0.0108 (0.2929) lr 3.6258e-03 eta 0:11:43
epoch [38/50] batch [20/200] time 0.285 (0.311) data 0.000 (0.030) loss 0.0131 (0.3180) lr 3.6258e-03 eta 0:13:22
epoch [38/50] batch [40/200] time 0.261 (0.288) data 0.000 (0.015) loss 0.0046 (0.2980) lr 3.6258e-03 eta 0:12:16
epoch [38/50] batch [60/200] time 0.260 (0.281) data 0.000 (0.010) loss 0.2350 (0.2602) lr 3.6258e-03 eta 0:11:53
epoch [38/50] batch [80/200] time 0.308 (0.281) data 0.000 (0.008) loss 0.2014 (0.2718) lr 3.6258e-03 eta 0:11:47
epoch [38/50] batch [100/200] time 0.261 (0.279) data 0.000 (0.006) loss 0.0055 (0.2754) lr 3.6258e-03 eta 0:11:36
epoch [38/50] batch [120/200] time 0.260 (0.276) data 0.000 (0.005) loss 0.0389 (0.3153) lr 3.6258e-03 eta 0:11:24
epoch [38/50] batch [140/200] time 0.260 (0.274) data 0.000 (0.004) loss 0.0032 (0.3180) lr 3.6258e-03 eta 0:11:14
epoch [38/50] batch [160/200] time 0.260 (0.272) data 0.000 (0.004) loss 0.4769 (0.3159) lr 3.6258e-03 eta 0:11:04
epoch [38/50] batch [180/200] time 0.261 (0.272) data 0.000 (0.003) loss 0.6652 (0.3344) lr 3.6258e-03 eta 0:10:57
epoch [38/50] batch [200/200] time 0.259 (0.271) data 0.000 (0.003) loss 0.0100 (0.3349) lr 3.1545e-03 eta 0:10:50
epoch [39/50] batch [20/200] time 0.260 (0.310) data 0.000 (0.030) loss 0.8333 (0.4532) lr 3.1545e-03 eta 0:12:16
epoch [39/50] batch [40/200] time 0.261 (0.285) data 0.000 (0.015) loss 2.1752 (0.4461) lr 3.1545e-03 eta 0:11:12
epoch [39/50] batch [60/200] time 0.262 (0.279) data 0.001 (0.010) loss 0.0532 (0.3859) lr 3.1545e-03 eta 0:10:52
epoch [39/50] batch [80/200] time 0.262 (0.274) data 0.000 (0.008) loss 0.0107 (0.4007) lr 3.1545e-03 eta 0:10:36
epoch [39/50] batch [100/200] time 0.261 (0.272) data 0.000 (0.006) loss 0.0311 (0.3733) lr 3.1545e-03 eta 0:10:24
epoch [39/50] batch [120/200] time 0.261 (0.271) data 0.000 (0.005) loss 1.6034 (0.3976) lr 3.1545e-03 eta 0:10:18
epoch [39/50] batch [140/200] time 0.261 (0.270) data 0.000 (0.004) loss 0.8466 (0.3991) lr 3.1545e-03 eta 0:10:11
epoch [39/50] batch [160/200] time 0.260 (0.269) data 0.000 (0.004) loss 0.7292 (0.3765) lr 3.1545e-03 eta 0:10:03
epoch [39/50] batch [180/200] time 0.260 (0.269) data 0.000 (0.004) loss 0.7088 (0.3641) lr 3.1545e-03 eta 0:09:56
epoch [39/50] batch [200/200] time 0.258 (0.268) data 0.000 (0.003) loss 0.4403 (0.3605) lr 2.7103e-03 eta 0:09:49
epoch [40/50] batch [20/200] time 0.272 (0.299) data 0.000 (0.029) loss 0.6799 (0.2261) lr 2.7103e-03 eta 0:10:51
epoch [40/50] batch [40/200] time 0.260 (0.280) data 0.000 (0.015) loss 0.5089 (0.2965) lr 2.7103e-03 eta 0:10:05
epoch [40/50] batch [60/200] time 0.262 (0.274) data 0.001 (0.010) loss 0.2421 (0.3300) lr 2.7103e-03 eta 0:09:46
epoch [40/50] batch [80/200] time 0.260 (0.271) data 0.000 (0.007) loss 0.3149 (0.3023) lr 2.7103e-03 eta 0:09:33
epoch [40/50] batch [100/200] time 0.265 (0.270) data 0.000 (0.006) loss 0.1289 (0.2827) lr 2.7103e-03 eta 0:09:26
epoch [40/50] batch [120/200] time 0.262 (0.268) data 0.000 (0.005) loss 1.5257 (0.2979) lr 2.7103e-03 eta 0:09:18
epoch [40/50] batch [140/200] time 0.285 (0.268) data 0.000 (0.004) loss 0.0015 (0.3172) lr 2.7103e-03 eta 0:09:11
epoch [40/50] batch [160/200] time 0.262 (0.267) data 0.000 (0.004) loss 1.0451 (0.3223) lr 2.7103e-03 eta 0:09:04
epoch [40/50] batch [180/200] time 0.260 (0.267) data 0.000 (0.003) loss 0.0942 (0.3111) lr 2.7103e-03 eta 0:08:59
epoch [40/50] batch [200/200] time 0.259 (0.266) data 0.000 (0.003) loss 0.1478 (0.3073) lr 2.2949e-03 eta 0:08:52
epoch [41/50] batch [20/200] time 0.261 (0.295) data 0.000 (0.029) loss 1.5741 (0.4012) lr 2.2949e-03 eta 0:09:44
epoch [41/50] batch [40/200] time 0.326 (0.286) data 0.000 (0.015) loss 1.5634 (0.3141) lr 2.2949e-03 eta 0:09:21
epoch [41/50] batch [60/200] time 0.260 (0.283) data 0.001 (0.010) loss 0.2186 (0.3324) lr 2.2949e-03 eta 0:09:08
epoch [41/50] batch [80/200] time 0.260 (0.277) data 0.000 (0.007) loss 0.0059 (0.3094) lr 2.2949e-03 eta 0:08:52
epoch [41/50] batch [100/200] time 0.264 (0.275) data 0.000 (0.006) loss 1.2652 (0.3536) lr 2.2949e-03 eta 0:08:43
epoch [41/50] batch [120/200] time 0.263 (0.274) data 0.000 (0.005) loss 0.0492 (0.3354) lr 2.2949e-03 eta 0:08:34
epoch [41/50] batch [140/200] time 0.309 (0.273) data 0.000 (0.004) loss 0.0624 (0.3303) lr 2.2949e-03 eta 0:08:28
epoch [41/50] batch [160/200] time 0.267 (0.272) data 0.000 (0.004) loss 0.0007 (0.3347) lr 2.2949e-03 eta 0:08:21
epoch [41/50] batch [180/200] time 0.261 (0.271) data 0.000 (0.003) loss 1.2624 (0.3348) lr 2.2949e-03 eta 0:08:13
epoch [41/50] batch [200/200] time 0.258 (0.271) data 0.000 (0.003) loss 0.5171 (0.3324) lr 1.9098e-03 eta 0:08:07
epoch [42/50] batch [20/200] time 0.260 (0.293) data 0.000 (0.030) loss 0.0957 (0.3350) lr 1.9098e-03 eta 0:08:42
epoch [42/50] batch [40/200] time 0.259 (0.279) data 0.000 (0.015) loss 0.0512 (0.3236) lr 1.9098e-03 eta 0:08:11
epoch [42/50] batch [60/200] time 0.259 (0.273) data 0.001 (0.010) loss 0.0985 (0.2797) lr 1.9098e-03 eta 0:07:55
epoch [42/50] batch [80/200] time 0.272 (0.274) data 0.000 (0.008) loss 0.0033 (0.2859) lr 1.9098e-03 eta 0:07:52
epoch [42/50] batch [100/200] time 0.256 (0.272) data 0.000 (0.006) loss 0.3152 (0.2883) lr 1.9098e-03 eta 0:07:41
epoch [42/50] batch [120/200] time 0.258 (0.270) data 0.000 (0.005) loss 0.4357 (0.2791) lr 1.9098e-03 eta 0:07:34
epoch [42/50] batch [140/200] time 0.259 (0.269) data 0.000 (0.004) loss 0.0117 (0.2791) lr 1.9098e-03 eta 0:07:25
epoch [42/50] batch [160/200] time 0.259 (0.268) data 0.000 (0.004) loss 0.0035 (0.2687) lr 1.9098e-03 eta 0:07:19
epoch [42/50] batch [180/200] time 0.259 (0.267) data 0.000 (0.003) loss 1.0305 (0.2664) lr 1.9098e-03 eta 0:07:12
epoch [42/50] batch [200/200] time 0.259 (0.266) data 0.000 (0.003) loss 0.0057 (0.2691) lr 1.5567e-03 eta 0:07:06
epoch [43/50] batch [20/200] time 0.260 (0.287) data 0.000 (0.024) loss 0.2292 (0.3443) lr 1.5567e-03 eta 0:07:33
epoch [43/50] batch [40/200] time 0.260 (0.276) data 0.000 (0.012) loss 0.3041 (0.2422) lr 1.5567e-03 eta 0:07:10
epoch [43/50] batch [60/200] time 0.258 (0.271) data 0.000 (0.008) loss 1.2349 (0.2779) lr 1.5567e-03 eta 0:06:58
epoch [43/50] batch [80/200] time 0.258 (0.268) data 0.000 (0.006) loss 0.0056 (0.2960) lr 1.5567e-03 eta 0:06:47
epoch [43/50] batch [100/200] time 0.260 (0.268) data 0.000 (0.005) loss 0.7712 (0.2966) lr 1.5567e-03 eta 0:06:41
epoch [43/50] batch [120/200] time 0.258 (0.267) data 0.000 (0.004) loss 0.6725 (0.3004) lr 1.5567e-03 eta 0:06:34
epoch [43/50] batch [140/200] time 0.258 (0.266) data 0.000 (0.004) loss 0.0230 (0.3330) lr 1.5567e-03 eta 0:06:27
epoch [43/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.2792 (0.3283) lr 1.5567e-03 eta 0:06:21
epoch [43/50] batch [180/200] time 0.259 (0.264) data 0.000 (0.003) loss 0.0108 (0.3322) lr 1.5567e-03 eta 0:06:15
epoch [43/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.4719 (0.3282) lr 1.2369e-03 eta 0:06:09
epoch [44/50] batch [20/200] time 0.258 (0.284) data 0.000 (0.024) loss 0.2226 (0.2553) lr 1.2369e-03 eta 0:06:32
epoch [44/50] batch [40/200] time 0.259 (0.272) data 0.000 (0.012) loss 1.2495 (0.2787) lr 1.2369e-03 eta 0:06:09
epoch [44/50] batch [60/200] time 0.258 (0.268) data 0.000 (0.008) loss 0.0710 (0.2638) lr 1.2369e-03 eta 0:05:58
epoch [44/50] batch [80/200] time 0.260 (0.267) data 0.000 (0.006) loss 0.0617 (0.2833) lr 1.2369e-03 eta 0:05:51
epoch [44/50] batch [100/200] time 0.260 (0.265) data 0.000 (0.005) loss 0.2406 (0.3104) lr 1.2369e-03 eta 0:05:44
epoch [44/50] batch [120/200] time 0.259 (0.264) data 0.000 (0.004) loss 0.4616 (0.2948) lr 1.2369e-03 eta 0:05:37
epoch [44/50] batch [140/200] time 0.260 (0.264) data 0.000 (0.004) loss 0.0629 (0.3469) lr 1.2369e-03 eta 0:05:32
epoch [44/50] batch [160/200] time 0.260 (0.264) data 0.000 (0.003) loss 0.0982 (0.3423) lr 1.2369e-03 eta 0:05:27
epoch [44/50] batch [180/200] time 0.260 (0.264) data 0.000 (0.003) loss 0.5665 (0.3389) lr 1.2369e-03 eta 0:05:21
epoch [44/50] batch [200/200] time 0.255 (0.263) data 0.000 (0.003) loss 0.2065 (0.3390) lr 9.5173e-04 eta 0:05:15
epoch [45/50] batch [20/200] time 0.265 (0.285) data 0.000 (0.024) loss 0.0160 (0.3178) lr 9.5173e-04 eta 0:05:36
epoch [45/50] batch [40/200] time 0.286 (0.276) data 0.000 (0.012) loss 1.1692 (0.3020) lr 9.5173e-04 eta 0:05:19
epoch [45/50] batch [60/200] time 0.274 (0.272) data 0.000 (0.008) loss 0.0109 (0.2832) lr 9.5173e-04 eta 0:05:10
epoch [45/50] batch [80/200] time 0.258 (0.269) data 0.000 (0.006) loss 0.0047 (0.2830) lr 9.5173e-04 eta 0:05:01
epoch [45/50] batch [100/200] time 0.258 (0.267) data 0.000 (0.005) loss 0.0044 (0.2592) lr 9.5173e-04 eta 0:04:53
epoch [45/50] batch [120/200] time 0.260 (0.266) data 0.000 (0.004) loss 0.0125 (0.2693) lr 9.5173e-04 eta 0:04:47
epoch [45/50] batch [140/200] time 0.257 (0.266) data 0.000 (0.004) loss 0.4447 (0.2683) lr 9.5173e-04 eta 0:04:41
epoch [45/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0007 (0.2669) lr 9.5173e-04 eta 0:04:35
epoch [45/50] batch [180/200] time 0.257 (0.264) data 0.000 (0.003) loss 0.0536 (0.2699) lr 9.5173e-04 eta 0:04:29
epoch [45/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.7856 (0.2816) lr 7.0224e-04 eta 0:04:23
epoch [46/50] batch [20/200] time 0.258 (0.284) data 0.000 (0.023) loss 0.0455 (0.1479) lr 7.0224e-04 eta 0:04:38
epoch [46/50] batch [40/200] time 0.258 (0.272) data 0.000 (0.012) loss 0.0271 (0.1837) lr 7.0224e-04 eta 0:04:21
epoch [46/50] batch [60/200] time 0.260 (0.269) data 0.001 (0.008) loss 0.3004 (0.1810) lr 7.0224e-04 eta 0:04:13
epoch [46/50] batch [80/200] time 0.258 (0.267) data 0.000 (0.006) loss 0.0075 (0.2090) lr 7.0224e-04 eta 0:04:05
epoch [46/50] batch [100/200] time 0.272 (0.268) data 0.000 (0.005) loss 0.5194 (0.2460) lr 7.0224e-04 eta 0:04:00
epoch [46/50] batch [120/200] time 0.272 (0.269) data 0.000 (0.004) loss 0.8900 (0.2957) lr 7.0224e-04 eta 0:03:56
epoch [46/50] batch [140/200] time 0.271 (0.270) data 0.000 (0.003) loss 0.0015 (0.3192) lr 7.0224e-04 eta 0:03:51
epoch [46/50] batch [160/200] time 0.271 (0.270) data 0.000 (0.003) loss 1.1043 (0.3464) lr 7.0224e-04 eta 0:03:46
epoch [46/50] batch [180/200] time 0.272 (0.270) data 0.000 (0.003) loss 0.2382 (0.3458) lr 7.0224e-04 eta 0:03:41
epoch [46/50] batch [200/200] time 0.257 (0.270) data 0.000 (0.002) loss 0.9229 (0.3455) lr 4.8943e-04 eta 0:03:36
epoch [47/50] batch [20/200] time 0.261 (0.291) data 0.000 (0.025) loss 0.7798 (0.3430) lr 4.8943e-04 eta 0:03:46
epoch [47/50] batch [40/200] time 0.260 (0.275) data 0.000 (0.013) loss 0.9870 (0.3869) lr 4.8943e-04 eta 0:03:28
epoch [47/50] batch [60/200] time 0.262 (0.269) data 0.000 (0.008) loss 0.1838 (0.3658) lr 4.8943e-04 eta 0:03:19
epoch [47/50] batch [80/200] time 0.258 (0.266) data 0.000 (0.006) loss 0.2376 (0.3458) lr 4.8943e-04 eta 0:03:11
epoch [47/50] batch [100/200] time 0.257 (0.265) data 0.000 (0.005) loss 0.1520 (0.3387) lr 4.8943e-04 eta 0:03:05
epoch [47/50] batch [120/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.8631 (0.3650) lr 4.8943e-04 eta 0:02:59
epoch [47/50] batch [140/200] time 0.258 (0.264) data 0.000 (0.004) loss 0.0173 (0.3638) lr 4.8943e-04 eta 0:02:54
epoch [47/50] batch [160/200] time 0.260 (0.263) data 0.000 (0.003) loss 0.4346 (0.3677) lr 4.8943e-04 eta 0:02:48
epoch [47/50] batch [180/200] time 0.258 (0.263) data 0.000 (0.003) loss 0.1240 (0.3725) lr 4.8943e-04 eta 0:02:43
epoch [47/50] batch [200/200] time 0.256 (0.263) data 0.000 (0.003) loss 0.0498 (0.3580) lr 3.1417e-04 eta 0:02:37
epoch [48/50] batch [20/200] time 0.259 (0.283) data 0.000 (0.023) loss 0.1783 (0.3293) lr 3.1417e-04 eta 0:02:44
epoch [48/50] batch [40/200] time 0.259 (0.272) data 0.000 (0.011) loss 0.2861 (0.2687) lr 3.1417e-04 eta 0:02:32
epoch [48/50] batch [60/200] time 0.263 (0.269) data 0.000 (0.008) loss 0.1706 (0.2752) lr 3.1417e-04 eta 0:02:25
epoch [48/50] batch [80/200] time 0.258 (0.268) data 0.000 (0.006) loss 0.5683 (0.2702) lr 3.1417e-04 eta 0:02:19
epoch [48/50] batch [100/200] time 0.259 (0.266) data 0.000 (0.005) loss 0.0124 (0.2699) lr 3.1417e-04 eta 0:02:13
epoch [48/50] batch [120/200] time 0.258 (0.266) data 0.000 (0.004) loss 1.0600 (0.2605) lr 3.1417e-04 eta 0:02:07
epoch [48/50] batch [140/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0006 (0.2610) lr 3.1417e-04 eta 0:02:01
epoch [48/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0017 (0.2761) lr 3.1417e-04 eta 0:01:56
epoch [48/50] batch [180/200] time 0.258 (0.264) data 0.000 (0.003) loss 0.2549 (0.2789) lr 3.1417e-04 eta 0:01:50
epoch [48/50] batch [200/200] time 0.257 (0.263) data 0.000 (0.002) loss 0.4784 (0.2789) lr 1.7713e-04 eta 0:01:45
epoch [49/50] batch [20/200] time 0.259 (0.297) data 0.000 (0.024) loss 0.3506 (0.3020) lr 1.7713e-04 eta 0:01:52
epoch [49/50] batch [40/200] time 0.259 (0.278) data 0.000 (0.012) loss 0.4678 (0.3156) lr 1.7713e-04 eta 0:01:40
epoch [49/50] batch [60/200] time 0.258 (0.272) data 0.000 (0.008) loss 1.6888 (0.3560) lr 1.7713e-04 eta 0:01:32
epoch [49/50] batch [80/200] time 0.259 (0.269) data 0.000 (0.006) loss 0.4962 (0.3277) lr 1.7713e-04 eta 0:01:26
epoch [49/50] batch [100/200] time 0.272 (0.268) data 0.000 (0.005) loss 0.5453 (0.3163) lr 1.7713e-04 eta 0:01:20
epoch [49/50] batch [120/200] time 0.263 (0.267) data 0.000 (0.004) loss 0.1890 (0.3021) lr 1.7713e-04 eta 0:01:14
epoch [49/50] batch [140/200] time 0.259 (0.266) data 0.000 (0.004) loss 0.0320 (0.2994) lr 1.7713e-04 eta 0:01:09
epoch [49/50] batch [160/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0240 (0.2936) lr 1.7713e-04 eta 0:01:03
epoch [49/50] batch [180/200] time 0.259 (0.265) data 0.000 (0.003) loss 0.0303 (0.2941) lr 1.7713e-04 eta 0:00:58
epoch [49/50] batch [200/200] time 0.256 (0.264) data 0.000 (0.003) loss 0.0084 (0.2932) lr 7.8853e-05 eta 0:00:52
epoch [50/50] batch [20/200] time 0.274 (0.297) data 0.000 (0.023) loss 0.1185 (0.2769) lr 7.8853e-05 eta 0:00:53
epoch [50/50] batch [40/200] time 0.277 (0.283) data 0.000 (0.012) loss 0.1703 (0.2435) lr 7.8853e-05 eta 0:00:45
epoch [50/50] batch [60/200] time 0.272 (0.282) data 0.000 (0.008) loss 1.2826 (0.3324) lr 7.8853e-05 eta 0:00:39
epoch [50/50] batch [80/200] time 0.275 (0.280) data 0.000 (0.006) loss 0.0206 (0.3008) lr 7.8853e-05 eta 0:00:33
epoch [50/50] batch [100/200] time 0.274 (0.279) data 0.000 (0.005) loss 0.0688 (0.2875) lr 7.8853e-05 eta 0:00:27
epoch [50/50] batch [120/200] time 0.275 (0.279) data 0.000 (0.004) loss 0.3529 (0.2805) lr 7.8853e-05 eta 0:00:22
epoch [50/50] batch [140/200] time 0.259 (0.276) data 0.000 (0.003) loss 0.0977 (0.2829) lr 7.8853e-05 eta 0:00:16
epoch [50/50] batch [160/200] time 0.261 (0.274) data 0.000 (0.003) loss 0.1122 (0.2721) lr 7.8853e-05 eta 0:00:10
epoch [50/50] batch [180/200] time 0.258 (0.273) data 0.000 (0.003) loss 0.2188 (0.2654) lr 7.8853e-05 eta 0:00:05
epoch [50/50] batch [200/200] time 0.257 (0.272) data 0.000 (0.002) loss 0.1368 (0.2680) lr 1.9733e-05 eta 0:00:00
Checkpoint saved to output/rpo/base2new/train_base/caltech101/shots_16/RPO/main_K24_ep50_batch4/seed1/prompt_learner/model.pth.tar-50
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,287
* correct: 1,263
* accuracy: 98.14%
* error: 1.86%
* macro_f1: 96.84%
Elapsed: 0:44:42
